{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb00c07",
   "metadata": {},
   "source": [
    "# Fine-Tuning Gemma 1B for Medical Record Entity Resolution\n",
    "\n",
    "Fine-tune **Gemma 3 1B** with LoRA to classify pairs of medical records as same-patient matches or non-matches. Uses only clinical data (conditions, medications, allergies, procedures, immunizations, observations) — no demographics.\n",
    "\n",
    "**Approach:**\n",
    "- Generate balanced training pairs from ground truth\n",
    "- **Strategy D**: Structured diff-friendly summaries (~760 tokens each, Opus ceiling F1=0.936)\n",
    "- Binary classification: \"True\" (match) or \"False\" (non-match)\n",
    "- LoRA fine-tuning on RunPod GPU (RTX A4000, bfloat16) — see `train_on_gpu.py` and `RUNPOD_GUIDE.md`\n",
    "\n",
    "**This notebook**: Explores the data pipeline (sections 3-6), then evaluates the GPU-trained adapter (sections 7-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c82c4c",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7601e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0\n",
      "MPS available: True\n",
      "Using device: mps\n",
      "Project root: /Users/alex/repos/Kaggle/SyntheticMass\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "# Add project root so shared/ imports work\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fae41",
   "metadata": {},
   "source": [
    "## 2. HuggingFace Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86b36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: abicyclerider\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, whoami\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.environ.get(\"HF_TOKEN\")\n",
    "if not token:\n",
    "    raise ValueError(\"HF_TOKEN not found. Create a .env file with: HF_TOKEN=hf_your_token_here\")\n",
    "\n",
    "login(token=token)\n",
    "print(f\"Logged in as: {whoami()['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06ca3d",
   "metadata": {},
   "source": [
    "## 3. Load Tokenizer\n",
    "\n",
    "Load the **Gemma 3 1B Instruct** tokenizer for token length analysis. The full model is loaded later for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0f9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from google/gemma-3-1b-it...\n",
      "Vocab size: 262,144\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"google/gemma-3-1b-it\"\n",
    "\n",
    "print(f\"Loading tokenizer from {MODEL_ID}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "print(f\"Vocab size: {tokenizer.vocab_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3868ca9",
   "metadata": {},
   "source": [
    "## 4. Load Data from Ground Truth\n",
    "\n",
    "Generate balanced pairs entirely from ground truth + medical records. No dependency on demographic matching scores.\n",
    "\n",
    "- **True match pairs**: Patients appearing at 2+ facilities yield cross-facility pairs\n",
    "- **Non-match pairs**: Random pairs from different true patient identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffd004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patient records: 1228\n",
      "Unique patients: 571\n",
      "Multi-facility patients: 354\n",
      "True match pairs: 1121\n",
      "Non-match pairs: 1121\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shared.data_loader import load_facility_patients\n",
    "from shared.ground_truth import (\n",
    "    load_ground_truth,\n",
    "    add_record_ids_to_ground_truth,\n",
    "    generate_true_pairs_from_ground_truth,\n",
    ")\n",
    "from shared.medical_records import load_medical_records, get_patient_records\n",
    "\n",
    "RUN_DIR = os.path.join(PROJECT_ROOT, \"output\", \"augmented\", \"run_20260203_071928\")\n",
    "\n",
    "# Load patients and create record_ids\n",
    "patients_df = load_facility_patients(RUN_DIR)\n",
    "patients_df['record_id'] = patients_df['facility_id'] + '_' + patients_df['id'].astype(str)\n",
    "\n",
    "# Load ground truth and add record_ids\n",
    "ground_truth_df = load_ground_truth(RUN_DIR)\n",
    "ground_truth_df = add_record_ids_to_ground_truth(ground_truth_df, patients_df)\n",
    "\n",
    "# Generate true match pairs\n",
    "true_pairs = generate_true_pairs_from_ground_truth(ground_truth_df)\n",
    "\n",
    "# Build record_id -> (patient_uuid, facility_id) mapping\n",
    "record_map = {}\n",
    "for _, row in patients_df.iterrows():\n",
    "    record_map[row['record_id']] = (row['id'], row['facility_id'])\n",
    "\n",
    "# Generate non-match pairs (balanced with true pairs)\n",
    "rid_to_true_id = (ground_truth_df.dropna(subset=['record_id'])\n",
    "                  .set_index('record_id')['true_patient_id'].to_dict())\n",
    "all_record_ids = list(rid_to_true_id.keys())\n",
    "\n",
    "random.seed(42)\n",
    "non_match_pairs = set()\n",
    "target = len(true_pairs)\n",
    "attempts = 0\n",
    "while len(non_match_pairs) < target and attempts < target * 20:\n",
    "    r1, r2 = random.sample(all_record_ids, 2)\n",
    "    if rid_to_true_id.get(r1) != rid_to_true_id.get(r2):\n",
    "        non_match_pairs.add(tuple(sorted([r1, r2])))\n",
    "    attempts += 1\n",
    "\n",
    "# Stats\n",
    "multi_facility = ground_truth_df.groupby('true_patient_id')['facility_id'].nunique()\n",
    "print(f\"Total patient records: {len(patients_df)}\")\n",
    "print(f\"Unique patients: {ground_truth_df['true_patient_id'].nunique()}\")\n",
    "print(f\"Multi-facility patients: {(multi_facility >= 2).sum()}\")\n",
    "print(f\"True match pairs: {len(true_pairs)}\")\n",
    "print(f\"Non-match pairs: {len(non_match_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7a9a7",
   "metadata": {},
   "source": [
    "## 5. Strategy D: Structured Diff-Friendly Summaries\n",
    "\n",
    "**Clinical data only** — no demographics (name, DOB, address, SSN, gender). Structured for pairwise comparison with conditions grouped by year, medications with date ranges, key observations, and procedures with years. ~760 tokens per summary (Opus achieves F1=0.936 on these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00435369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Strategy D summaries for 1190 unique records...\n",
      "\n",
      "Single summary token lengths:\n",
      "  Mean: 830, Median: 692\n",
      "  Min: 6, Max: 5247\n",
      "  95th pctl: 1978\n",
      "\n",
      "Pair token lengths (summaries only, sample of 400):\n",
      "  Mean: 1513, Max: 4673\n"
     ]
    }
   ],
   "source": [
    "# Load all medical records\n",
    "medical_records = load_medical_records(RUN_DIR)\n",
    "\n",
    "\n",
    "def summarize_diff_friendly(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Structured for pairwise comparison, grouped by year. Target ~800 tokens.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = []\n",
    "\n",
    "    # CONDITIONS - grouped by onset year\n",
    "    cond_df = records.get('conditions')\n",
    "    if cond_df is not None:\n",
    "        cond_df = cond_df.copy()\n",
    "        cond_df['year'] = pd.to_datetime(cond_df['START'], errors='coerce').dt.year\n",
    "        cond_df['is_ongoing'] = cond_df['STOP'].isna() | (cond_df['STOP'].astype(str).str.strip() == '')\n",
    "        lines = [\"CONDITIONS:\"]\n",
    "        for year, grp in sorted(cond_df.groupby('year')):\n",
    "            if pd.isna(year):\n",
    "                continue\n",
    "            descs = []\n",
    "            for _, row in grp.iterrows():\n",
    "                status = \" *\" if row['is_ongoing'] else \"\"\n",
    "                descs.append(f\"{row['DESCRIPTION']}{status}\")\n",
    "            lines.append(f\"  {int(year)}: {'; '.join(descs)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # MEDICATIONS - drug (start_year-end_year or ongoing)\n",
    "    meds_df = records.get('medications')\n",
    "    if meds_df is not None:\n",
    "        meds_df = meds_df.copy()\n",
    "        lines = [\"MEDICATIONS:\"]\n",
    "        for desc, grp in meds_df.groupby('DESCRIPTION', sort=False):\n",
    "            start_dt = pd.to_datetime(grp['START'], errors='coerce').min()\n",
    "            is_current = grp['STOP'].isna().any() | (grp['STOP'].astype(str).str.strip() == '').any()\n",
    "            if is_current:\n",
    "                period = f\"{start_dt.year}\\u2013ongoing\" if pd.notna(start_dt) else \"ongoing\"\n",
    "            else:\n",
    "                end_dt = pd.to_datetime(grp['STOP'], errors='coerce').max()\n",
    "                if pd.notna(start_dt) and pd.notna(end_dt):\n",
    "                    period = f\"{start_dt.year}\\u2013{end_dt.year}\"\n",
    "                else:\n",
    "                    period = \"unknown\"\n",
    "            lines.append(f\"- {desc} ({period})\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # ALLERGIES - flat list\n",
    "    allg_df = records.get('allergies')\n",
    "    if allg_df is not None:\n",
    "        names = sorted(allg_df['DESCRIPTION'].unique())\n",
    "        sections.append(\"ALLERGIES: \" + \"; \".join(names))\n",
    "\n",
    "    # KEY OBSERVATIONS - latest 2 values per metric\n",
    "    obs_df = records.get('observations')\n",
    "    if obs_df is not None:\n",
    "        obs_df = obs_df.copy()\n",
    "        obs_df['date_dt'] = pd.to_datetime(obs_df['DATE'], errors='coerce')\n",
    "        key_obs = [\n",
    "            'Body Height', 'Body Weight', 'Body Mass Index',\n",
    "            'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
    "            'Hemoglobin A1c/Hemoglobin.total in Blood',\n",
    "            'Glucose', 'Total Cholesterol',\n",
    "        ]\n",
    "        lines = [\"OBSERVATIONS:\"]\n",
    "        for obs_name in key_obs:\n",
    "            match = obs_df[obs_df['DESCRIPTION'].str.contains(obs_name, case=False, na=False)]\n",
    "            if match.empty:\n",
    "                continue\n",
    "            recent = match.sort_values('date_dt').tail(2)\n",
    "            vals = []\n",
    "            for _, row in recent.iterrows():\n",
    "                v = row.get('VALUE', '')\n",
    "                u = row.get('UNITS', '')\n",
    "                d = str(row.get('DATE', ''))[:10]\n",
    "                if pd.notna(v) and str(v).strip():\n",
    "                    u_str = f\" {u}\" if pd.notna(u) and u else \"\"\n",
    "                    vals.append(f\"{v}{u_str} ({d})\")\n",
    "            if vals:\n",
    "                lines.append(f\"- {obs_name}: {', '.join(vals)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # PROCEDURES - with years, chronological\n",
    "    proc_df = records.get('procedures')\n",
    "    if proc_df is not None:\n",
    "        proc_df = proc_df.copy()\n",
    "        proc_df['year'] = pd.to_datetime(proc_df['START'], errors='coerce').dt.year\n",
    "        lines = [\"PROCEDURES:\"]\n",
    "        for desc, grp in proc_df.groupby('DESCRIPTION', sort=False):\n",
    "            years = sorted(grp['year'].dropna().unique())\n",
    "            year_strs = [str(int(y)) for y in years]\n",
    "            lines.append(f\"- {desc} ({', '.join(year_strs)})\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    return \"\\n\\n\".join(sections) if sections else \"No clinical records available.\"\n",
    "\n",
    "\n",
    "# Build summary cache for all needed records\n",
    "all_needed = set()\n",
    "for r1, r2 in true_pairs | non_match_pairs:\n",
    "    all_needed.add(r1)\n",
    "    all_needed.add(r2)\n",
    "\n",
    "print(f\"Generating Strategy D summaries for {len(all_needed)} unique records...\")\n",
    "summary_cache = {}\n",
    "for rid in all_needed:\n",
    "    if rid in record_map:\n",
    "        pid, fid = record_map[rid]\n",
    "        summary_cache[rid] = summarize_diff_friendly(pid, fid, medical_records)\n",
    "\n",
    "# Token length stats\n",
    "token_lengths = [len(tokenizer.encode(s)) for s in summary_cache.values()]\n",
    "pair_lengths = []\n",
    "for r1, r2 in list(true_pairs)[:200] + list(non_match_pairs)[:200]:\n",
    "    if r1 in summary_cache and r2 in summary_cache:\n",
    "        combined = summary_cache[r1] + \"\\n\\n\" + summary_cache[r2]\n",
    "        pair_lengths.append(len(tokenizer.encode(combined)))\n",
    "\n",
    "print(f\"\\nSingle summary token lengths:\")\n",
    "print(f\"  Mean: {np.mean(token_lengths):.0f}, Median: {np.median(token_lengths):.0f}\")\n",
    "print(f\"  Min: {min(token_lengths)}, Max: {max(token_lengths)}\")\n",
    "print(f\"  95th pctl: {np.percentile(token_lengths, 95):.0f}\")\n",
    "print(f\"\\nPair token lengths (summaries only, sample of {len(pair_lengths)}):\")\n",
    "print(f\"  Mean: {np.mean(pair_lengths):.0f}, Max: {max(pair_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ls0kl5hosu",
   "metadata": {},
   "source": [
    "### Example Pairs: Match vs Non-Match (Strategy D)\n",
    "\n",
    "What does the model actually see? Here are a few true matches (same patient at different facilities) and non-matches (different patients) side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gau18llvqup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  TRUE MATCH  |  facility_002 vs facility_003\n",
      "======================================================================\n",
      "\n",
      "--- Record A (facility_002) ---\n",
      "CONDITIONS:\n",
      "  2010: Medication review due (situation); Stress (finding)\n",
      "  2015: Abnormal findings diagnostic imaging heart+coronary circulat (finding) *\n",
      "  2018: Part-time employment (finding); Limited social contact (finding); Victim of intimate partner abuse (finding)\n",
      "  2019: Acute viral pharyngitis (disorder)\n",
      "  2022: Medication review due (situation); Full-time employment (finding)\n",
      "  2024: Severe anxiety (panic) (finding)\n",
      "\n",
      "MEDICATIONS:\n",
      "- Hydrochlorothiazide 25 MG Oral Tablet (2014–2025)\n",
      "- lisinopril 10 MG Oral Tablet (2014–2025)\n",
      "- amLODIPine 2.5 MG Oral Tablet (2018–2025)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 171.6 cm (2022-03-24), 171.6 cm (2024-04-04)\n",
      "- Body Weight: 80.4 kg (2022-03-24), 80.4 kg (2024-04-04)\n",
      "- Body Mass Index: 27.3 kg/m2 (2022-03-24), 27.3 kg/m2 (2024-04-04)\n",
      "- Systolic Blood Pressure: 99.0 mm[Hg] (2022-03-24), 96.0 mm[Hg] (2024-04-04)\n",
      "- Diastolic Blood Pressure: 66.0 mm[Hg] (2022-03-24), 72.0 mm[Hg] (2024-04-04)\n",
      "- Hemoglobin A1c/Hemoglobin.total in Blood: 6.3 % (2022-03-24), 6.3 % (2024-04-04)\n",
      "- Glucose: 87.0 mg/dL (2022-03-24), 68.1 mg/dL (2024-04-04)\n",
      "\n",
      "PROCEDURES:\n",
      "- Assessment of health and social care needs (procedure) (2018, 2022, 2024)\n",
      "- Assessment using Morse Fall Scale (procedure) (2018, 2024)\n",
      "- Screening for domestic abuse (procedure) (2018, 2024)\n",
      "- Depression screening (procedure) (2018, 2022, 2024)\n",
      "- Depression screening using Patient Health Questionnaire Two-Item score (procedure) (2018, 2022, 2024)\n",
      "- Throat culture (procedure) (2019)\n",
      "- Medication Reconciliation (procedure) (2022)\n",
      "- Assessment of anxiety (procedure) (2024)\n",
      "- Assessment of substance use (procedure) (2024)\n",
      "- Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure) (2024)\n",
      "\n",
      "--- Record B (facility_003) ---\n",
      "CONDITIONS:\n",
      "  1944: Medication review due (situation); Medication review due (situation)\n",
      "  1945: Medication review due (situation); Medication review due (situation)\n",
      "  1946: Medication review due (situation); Medication review due (situation)\n",
      "  1947: Medication review due (situation); Medication review due (situation)\n",
      "  1948: Medication review due (situation)\n",
      "  1950: Medication review due (situation)\n",
      "  1952: Medication review due (situation)\n",
      "  1953: Medication review due (situation); Medication review due (situation)\n",
      "  1954: Medication review due (situation)\n",
      "  1955: Medication review due (situation)\n",
      "  1956: Medication review due (situation)\n",
      "  1957: Medication review due (situation); Medication review due (situation)\n",
      "  1958: Medication review due (situation)\n",
      "  1962: Received higher education (finding) *\n",
      "  1963: Medication review due (situation)\n",
      "  1966: Medication review due (situation)\n",
      "  1969: Stress (finding); History of tubal ligation (situation) *\n",
      "  1976: Medication review due (situation); Stress (finding)\n",
      "  1982: Medication review due (situation)\n",
      "  1984: Stress (finding)\n",
      "  1986: Medication review due (situation); Body mass index 30+ - obesity (finding) *\n",
      "  1992: Prediabetes *; Anemia (disorder) *\n",
      "  1994: Medication review due (situation); Stress (finding)\n",
      "  1996: Medication review due (situation)\n",
      "  1998: Medication review due (situation); Not in labor force (finding); Stress (finding)\n",
      "  2001: Stress (finding)\n",
      "  2003: Medication review due (situation)\n",
      "  2004: Medication review due (situation)\n",
      "  2005: Not in labor force (finding)\n",
      "\n",
      "======================================================================\n",
      "  TRUE MATCH  |  facility_002 vs facility_004\n",
      "======================================================================\n",
      "\n",
      "--- Record A (facility_002) ---\n",
      "CONDITIONS:\n",
      "  2025: Sinusitis (disorder); Chronic sinusitis (disorder) *\n",
      "\n",
      "MEDICATIONS:\n",
      "- Amoxicillin 250 MG / Clavulanate 125 MG Oral Tablet (2025–2025)\n",
      "\n",
      "--- Record B (facility_004) ---\n",
      "CONDITIONS:\n",
      "  2006: Risk activity involvement (finding) *\n",
      "  2009: Housing unsatisfactory (finding) *; Received higher education (finding) *; Full-time employment (finding); Stress (finding); Has a criminal record (finding) *\n",
      "  2013: Body mass index 30+ - obesity (finding) *\n",
      "  2016: Medication review due (situation)\n",
      "  2019: Medication review due (situation); Not in labor force (finding)\n",
      "\n",
      "MEDICATIONS:\n",
      "- Loratadine 5 MG Chewable Tablet (1992–ongoing)\n",
      "- NDA020800 0.3 ML Epinephrine 1 MG/ML Auto-Injector (1992–ongoing)\n",
      "\n",
      "ALLERGIES: Allergy to substance (finding); Fish (substance); Mold (organism)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 177.0 cm (2016-10-16), 177.0 cm (2019-10-20)\n",
      "- Body Weight: 102.3 kg (2016-10-16), 98.2 kg (2019-10-20)\n",
      "- Body Mass Index: 32.7 kg/m2 (2016-10-16), 31.3 kg/m2 (2019-10-20)\n",
      "- Systolic Blood Pressure: 113.0 mm[Hg] (2016-10-16), 112.0 mm[Hg] (2019-10-20)\n",
      "- Diastolic Blood Pressure: 84.0 mm[Hg] (2016-10-16), 88.0 mm[Hg] (2019-10-20)\n",
      "\n",
      "PROCEDURES:\n",
      "- Medication Reconciliation (procedure) (2016, 2019)\n",
      "- Assessment of health and social care needs (procedure) (2016, 2019)\n",
      "- Assessment of anxiety (procedure) (2016)\n",
      "- Depression screening (procedure) (2016)\n",
      "- Depression screening using Patient Health Questionnaire Two-Item score (procedure) (2016)\n",
      "- Depression screening using Patient Health Questionnaire Nine Item score (procedure) (2016)\n",
      "- Assessment of substance use (procedure) (2019)\n",
      "- Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure) (2019)\n",
      "\n",
      "======================================================================\n",
      "  NON-MATCH  |  facility_002 vs facility_003\n",
      "======================================================================\n",
      "\n",
      "--- Record A (facility_002) ---\n",
      "CONDITIONS:\n",
      "  2013: Appendicitis *; History of appendectomy *\n",
      "  2016: Medication review due (situation)\n",
      "  2017: Risk activity involvement (finding)\n",
      "  2018: Sprain (morphologic abnormality); Sprain of ankle; Medication review due (situation)\n",
      "  2019: Medication review due (situation)\n",
      "  2021: Suspected COVID-19; Headache (finding); Cough (finding); Fatigue (finding); Nausea (finding); Vomiting symptom (finding); Fever (finding); Loss of taste (finding); COVID-19\n",
      "  2022: Medication review due (situation); Received higher education (finding) *; Full-time employment (finding) *; Social isolation (finding)\n",
      "  2023: Medication review due (situation); Victim of intimate partner abuse (finding) *\n",
      "\n",
      "MEDICATIONS:\n",
      "- Acetaminophen 325 MG Oral Tablet (2018–2018)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 172.7 cm (2022-11-04), 173.1 cm (2023-11-10)\n",
      "- Body Weight: 61.9 kg (2022-11-04), 62.7 kg (2023-11-10)\n",
      "- Body Mass Index: 20.9 kg/m2 (2023-11-10), 26.6 % (2023-11-10)\n",
      "- Systolic Blood Pressure: 102.0 mm[Hg] (2022-11-04), 102.0 mm[Hg] (2023-11-10)\n",
      "- Diastolic Blood Pressure: 78.0 mm[Hg] (2022-11-04), 81.0 mm[Hg] (2023-11-10)\n",
      "\n",
      "PROCEDURES:\n",
      "- Assessment of anxiety (procedure) (2016, 2022)\n",
      "- Depression screening (procedure) (2016, 2017, 2018, 2020, 2021, 2022, 2023)\n",
      "- Depression screening using Patient Health Questionnaire Nine Item score (procedure) (2016, 2017, 2018, 2020, 2021)\n",
      "- Assessment of substance use (procedure) (2016, 2017, 2018, 2021, 2023)\n",
      "- Assessment using Car  Relax  Alone  Forget  Friends  Trouble Screening Test (procedure) (2016, 2017, 2018, 2021)\n",
      "- Anticipatory guidance (procedure) (2016, 2018, 2021)\n",
      "- Medication Reconciliation (procedure) (2017, 2018, 2021, 2022, 2023)\n",
      "- Health risks education (procedure) (2017)\n",
      "- Face mask (physical object) (2021)\n",
      "- Assessment of health and social care needs (procedure) (2022, 2023)\n",
      "- Depression screening using Patient Health Questionnaire Two-Item score (procedure) (2022, 2023)\n",
      "- Screening for domestic abuse (procedure) (2023)\n",
      "- Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure) (2023)\n",
      "\n",
      "--- Record B (facility_003) ---\n",
      "CONDITIONS:\n",
      "  1960: Medication review due (situation)\n",
      "  1961: Medication review due (situation); Medication review due (situation); Medication review due (situation)\n",
      "  1962: Medication review due (situation)\n",
      "  1965: Medication review due (situation)\n",
      "  1967: Medication review due (situation)\n",
      "  1969: Medication review due (situation)\n",
      "  1970: Medication review due (situation)\n",
      "  1973: Medication review due (situation)\n",
      "  1977: Medication review due (situation)\n",
      "  1978: Only received primary school education (finding) *; Part-time employment (finding); Limited social contact (finding); Stress (finding)\n",
      "  1979: Medication review due (situation)\n",
      "  1980: Stress (finding); Medication review due (situation)\n",
      "  1991: Medication review due (situation); Body mass index 30+ - obesity (finding) *; Part-time employment (finding)\n",
      "  1994: Medication review due (situation)\n",
      "  1997: Essential hypertension (disorder) *; Medication review due (situation)\n",
      "  1998: Part-time employment (finding)\n",
      "  1999: Stress (finding)\n",
      "  2001: Medication review due (situation); Medication review due (situation)\n",
      "  2003: Chronic kidney disease stage 1 (disorder) *; Disorder of kidney due to diabetes mellitus (disorder) *; Stress (finding)\n",
      "  2004: Medication review due (situation); Stress (finding)\n",
      "  2005: Part-time employment (finding); Limited social contact (finding)\n",
      "  2006: Stress (finding)\n",
      "  2007: Chronic kidney disease stage 2 (disorder) *; Microalbuminuria due to type 2 diabetes mellitus (disorder) *\n",
      "  2008: Medication review due (situation); Stress (finding)\n",
      "  2009: Limited social contact (finding); Metabolic syndrome X (disorder) *; Prediabetes *; Stress (finding)\n",
      "  2010: Medication review due (situation); Part-time employment (finding); Limited social contact (finding); Medication review due (situation); Medication review due (situation); Stress (finding)\n",
      "  2011: Medication review due (situation); Part-time employment (finding); Limited social contact (finding)\n",
      "  2012: Medication review due (situation); Chronic kidney disease stage 3 (disorder) *; Proteinuria due to type 2 diabetes mellitus (disorder) *; Stress (finding); Medication review due (situation)\n",
      "  2013: Medication review due (situation); Medication review due (situation); Stress (finding); Medication review due (situation); Part-time employment (finding)\n",
      "  2014: Medication review due (situation); Medication review due (situation); Part-time employment (finding); Stress (finding); Medication review due (situation)\n",
      "  2015: Medication review due (situation); Medication review due (situation); Has a criminal record (finding) *; Stress (finding); Not in labor force (finding)\n",
      "  2016: Medication review due (situation); Part-time employment (finding); Full-time employment (finding); Medication review due (situation); Limited social contact (finding)\n",
      "  2017: Medication review due (situation); Medication review due (situation); Stress (finding); Acute bronchitis (disorder); Part-time employment (finding); Stress (finding); Victim of intimate partner abuse (finding)\n",
      "  2018: Not in labor force (finding); Full-time employment (finding); Limited social contact (finding); Medication review due (situation); Viral sinusitis (disorder); Medication review due (situation); Medication review due (situation)\n",
      "\n",
      "MEDICATIONS:\n",
      "- lisinopril 10 MG Oral Tablet (1997–2018)\n",
      "- Hydrochlorothiazide 25 MG Oral Tablet (1997–2018)\n",
      "- insulin isophane  human 70 UNT/ML / insulin  regular  human 30 UNT/ML Injectable Suspension [Humulin] (2009–2018)\n",
      "- Acetaminophen 21.7 MG/ML / Dextromethorphan Hydrobromide 1 MG/ML / doxylamine succinate 0.417 MG/ML Oral Solution (2017–2017)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 156.6 cm (2018-08-29), 156.6 cm (2018-09-12)\n",
      "- Body Weight: 69.3 kg (2018-08-29), 69.4 kg (2018-09-12)\n",
      "- Body Mass Index: 28.3 kg/m2 (2018-08-29), 28.3 kg/m2 (2018-09-12)\n",
      "- Systolic Blood Pressure: 108.0 mm[Hg] (2018-08-29), 113.0 mm[Hg] (2018-09-12)\n",
      "- Diastolic Blood Pressure: 64.0 mm[Hg] (2018-08-29), 66.0 mm[Hg] (2018-09-12)\n",
      "- Hemoglobin A1c/Hemoglobin.total in Blood: 3.0 % (2018-09-12), 3.0 % (2018-09-19)\n",
      "- Glucose: 71.4 mg/dL (2018-09-19), Urine glucose test = ++ (finding) {nominal} (2018-09-19)\n",
      "\n",
      "PROCEDURES:\n",
      "- Assessment of health and social care needs (procedure) (2016, 2017, 2018)\n",
      "- Assessment of anxiety (procedure) (2016, 2017, 2018)\n",
      "- Depression screening (procedure) (2016, 2017, 2018)\n",
      "- Depression screening using Patient Health Questionnaire Two-Item score (procedure) (2016, 2017, 2018)\n",
      "- Depression screening using Patient Health Questionnaire Nine Item score (procedure) (2016)\n",
      "- Assessment of substance use (procedure) (2016, 2017, 2018)\n",
      "- Screening for drug abuse (procedure) (2016, 2018)\n",
      "- Screening for domestic abuse (procedure) (2016, 2017, 2018)\n",
      "- Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure) (2016, 2017, 2018)\n",
      "- Medication Reconciliation (procedure) (2016, 2017, 2018)\n",
      "\n",
      "======================================================================\n",
      "  NON-MATCH  |  facility_003 vs facility_004\n",
      "======================================================================\n",
      "\n",
      "--- Record A (facility_003) ---\n",
      "CONDITIONS:\n",
      "  1998: Medication review due (situation); Medication review due (situation)\n",
      "  1999: Medication review due (situation)\n",
      "  2000: Medication review due (situation)\n",
      "  2002: Medication review due (situation)\n",
      "  2003: Medication review due (situation)\n",
      "  2005: Medication review due (situation)\n",
      "  2006: Medication review due (situation)\n",
      "  2007: Medication review due (situation)\n",
      "  2008: Medication review due (situation); Medication review due (situation)\n",
      "  2010: Medication review due (situation)\n",
      "  2011: Medication review due (situation)\n",
      "  2016: Only received primary school education (finding) *; Full-time employment (finding); Limited social contact (finding)\n",
      "  2017: Laceration - injury (disorder); Laceration of thigh; Medication review due (situation); Part-time employment (finding); Stress (finding)\n",
      "  2020: Medication review due (situation)\n",
      "  2023: Medication review due (situation) *; Full-time employment (finding) *\n",
      "  2024: Sprain (morphologic abnormality); Sprain of ankle\n",
      "\n",
      "MEDICATIONS:\n",
      "- Naproxen sodium 220 MG Oral Tablet (2017–2017)\n",
      "- Ibuprofen 200 MG Oral Tablet (2024–2024)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 178.1 cm (2020-10-26), 178.1 cm (2023-10-30)\n",
      "- Body Weight: 77.1 kg (2020-10-26), 81.5 kg (2023-10-30)\n",
      "- Body Mass Index: 24.3 kg/m2 (2020-10-26), 25.7 kg/m2 (2023-10-30)\n",
      "- Systolic Blood Pressure: 119.0 mm[Hg] (2020-10-26), 118.0 mm[Hg] (2023-10-30)\n",
      "- Diastolic Blood Pressure: 75.0 mm[Hg] (2020-10-26), 79.0 mm[Hg] (2023-10-30)\n",
      "\n",
      "PROCEDURES:\n",
      "- Medication Reconciliation (procedure) (2016, 2017, 2020)\n",
      "- Assessment of health and social care needs (procedure) (2016, 2017, 2020, 2023)\n",
      "- Assessment of anxiety (procedure) (2016, 2023)\n",
      "- Assessment of substance use (procedure) (2016, 2017, 2020, 2023)\n",
      "- Screening for drug abuse (procedure) (2016, 2017, 2023)\n",
      "- Suture open wound (2017)\n",
      "- Depression screening (procedure) (2017, 2020, 2023)\n",
      "- Depression screening using Patient Health Questionnaire Two-Item score (procedure) (2017, 2020, 2023)\n",
      "- Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure) (2020)\n",
      "- Screening for domestic abuse (procedure) (2023)\n",
      "\n",
      "--- Record B (facility_004) ---\n",
      "CONDITIONS:\n",
      "  2024: Medication review due (situation); Viral sinusitis (disorder)\n",
      "  2025: Medication review due (situation); Fracture of bone (disorder) *; Fracture of ankle *\n",
      "  2026: Medication review due (situation) *\n",
      "\n",
      "MEDICATIONS:\n",
      "- Acetaminophen 160 MG Chewable Tablet (2025–ongoing)\n",
      "\n",
      "OBSERVATIONS:\n",
      "- Body Height: 94.5 cm (2025-07-15), 98.7 cm (2026-01-13)\n",
      "- Body Weight: 19.2 kg (2025-07-15), 19.7 kg (2026-01-13)\n",
      "- Body Mass Index: 20.2 kg/m2 (2026-01-13), 99.7 % (2026-01-13)\n",
      "- Systolic Blood Pressure: 123.0 mm[Hg] (2025-07-15), 119.0 mm[Hg] (2026-01-13)\n",
      "- Diastolic Blood Pressure: 85.0 mm[Hg] (2025-07-15), 80.0 mm[Hg] (2026-01-13)\n",
      "\n",
      "PROCEDURES:\n",
      "- Medication Reconciliation (procedure) (2025)\n",
      "- Ankle X-ray (2025)\n",
      "- Bone immobilization (2025)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 2 true match pairs and 2 non-match pairs\n",
    "sample_true = list(true_pairs)[:2]\n",
    "sample_false = list(non_match_pairs)[:2]\n",
    "\n",
    "for label_name, pairs in [(\"TRUE MATCH\", sample_true), (\"NON-MATCH\", sample_false)]:\n",
    "    for r1, r2 in pairs:\n",
    "        if r1 not in summary_cache or r2 not in summary_cache:\n",
    "            continue\n",
    "        fac1 = r1.split('_')[0] + '_' + r1.split('_')[1]\n",
    "        fac2 = r2.split('_')[0] + '_' + r2.split('_')[1]\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  {label_name}  |  {fac1} vs {fac2}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\n--- Record A ({fac1}) ---\")\n",
    "        print(summary_cache[r1])\n",
    "        print(f\"\\n--- Record B ({fac2}) ---\")\n",
    "        print(summary_cache[r2])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91160b52",
   "metadata": {},
   "source": [
    "## 6. Load Test Set from Hub\n",
    "\n",
    "Load the test split from the HF Hub dataset (built by `prepare_dataset.py`). This guarantees no overlap with the training data used on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b2ed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from abicyclerider/entity-resolution-pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4934e803ebf84eb9a30fb0a6f9210c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/543 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec47c20813a54fafbf6fd4dfbbd48b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/1.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bd98fce5534b3ab08e2c0a77dee9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/eval-00000-of-00001.parquet:   0%|          | 0.00/324k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb38aa1994a4e6591adea214b1a16d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/326k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb562d21382c423082d48ff992f2d503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d988580d7a624bda90e2ed94e653b162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23f3d7f7a4a49c3a166a293010888ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splits:\n",
      "  Train: 1568\n",
      "  Eval:  336\n",
      "  Test:  338 (169 match + 169 non-match)\n",
      "\n",
      "Test sequence lengths:\n",
      "  Mean: 1566, Max: 4555\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_REPO = \"abicyclerider/entity-resolution-pairs\"\n",
    "\n",
    "print(f\"Loading dataset from {DATASET_REPO}...\")\n",
    "dataset = load_dataset(DATASET_REPO)\n",
    "\n",
    "# Extract test prompts and labels\n",
    "test_prompts = []\n",
    "test_labels = []\n",
    "for example in dataset[\"test\"]:\n",
    "    test_prompts.append(example[\"messages\"][0][\"content\"])\n",
    "    test_labels.append(example[\"messages\"][1][\"content\"] == \"True\")\n",
    "\n",
    "n_match = sum(test_labels)\n",
    "n_non = len(test_labels) - n_match\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Train: {len(dataset['train'])}\")\n",
    "print(f\"  Eval:  {len(dataset['eval'])}\")\n",
    "print(f\"  Test:  {len(dataset['test'])} ({n_match} match + {n_non} non-match)\")\n",
    "\n",
    "# Token length stats for test set\n",
    "test_lengths = []\n",
    "for example in dataset[\"test\"]:\n",
    "    text = tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
    "    test_lengths.append(len(tokenizer.encode(text)))\n",
    "print(f\"\\nTest sequence lengths:\")\n",
    "print(f\"  Mean: {np.mean(test_lengths):.0f}, Max: {max(test_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fbce01",
   "metadata": {},
   "source": [
    "## 7. Benchmark Base Model (Before Fine-Tuning)\n",
    "\n",
    "Run the base Gemma 1B model on the Hub test set with greedy decoding. This gives us a baseline to compare against after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c54037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/gemma-3-1b-it...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0449a0cb9ef246679a7f745f98face44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking base model on 338 test pairs...\n",
      "  50/338...\n",
      "  100/338...\n",
      "  150/338...\n",
      "  200/338...\n",
      "  250/338...\n",
      "  300/338...\n",
      "\n",
      "Base Model (336 parseable / 338 total):\n",
      "    accuracy: 0.527\n",
      "   precision: 0.523\n",
      "      recall: 0.675\n",
      "          f1: 0.589\n",
      "\n",
      "Confusion matrix (rows=actual, cols=predicted):\n",
      "[[ 63 104]\n",
      " [ 55 114]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "def predict_match(model, tokenizer, prompt):\n",
    "    \"\"\"Predict whether two medical records match from a formatted prompt.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(\n",
    "        input_text, return_tensors=\"pt\", truncation=True, max_length=4096\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=8, do_sample=False)\n",
    "\n",
    "    response = tokenizer.decode(\n",
    "        outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True\n",
    "    ).strip().lower()\n",
    "\n",
    "    if \"true\" in response:\n",
    "        return True\n",
    "    elif \"false\" in response:\n",
    "        return False\n",
    "    return None\n",
    "\n",
    "\n",
    "def evaluate_predictions(labels, preds):\n",
    "    \"\"\"Compute classification metrics.\"\"\"\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, zero_division=0),\n",
    "        'recall': recall_score(labels, preds, zero_division=0),\n",
    "        'f1': f1_score(labels, preds, zero_division=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation(model, tokenizer, test_prompts, test_labels, label=\"Model\"):\n",
    "    \"\"\"Run model on test prompts and return metrics + predictions.\"\"\"\n",
    "    preds, labels, indices = [], [], []\n",
    "    for i, (prompt, true_label) in enumerate(zip(test_prompts, test_labels)):\n",
    "        pred = predict_match(model, tokenizer, prompt)\n",
    "        if pred is not None:\n",
    "            preds.append(pred)\n",
    "            labels.append(true_label)\n",
    "            indices.append(i)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  {i+1}/{len(test_prompts)}...\")\n",
    "\n",
    "    metrics = evaluate_predictions(labels, preds)\n",
    "    print(f\"\\n{label} ({len(preds)} parseable / {len(test_prompts)} total):\")\n",
    "    for m, v in metrics.items():\n",
    "        print(f\"  {m:>10s}: {v:.3f}\")\n",
    "    print(f\"\\nConfusion matrix (rows=actual, cols=predicted):\")\n",
    "    print(confusion_matrix(labels, preds))\n",
    "    return metrics, preds, labels\n",
    "\n",
    "\n",
    "# Load base model\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, dtype=torch.float32, device_map=\"mps\",\n",
    ")\n",
    "\n",
    "print(f\"\\nBenchmarking base model on {len(test_prompts)} test pairs...\")\n",
    "base_metrics, base_preds, base_labels = run_evaluation(\n",
    "    model, tokenizer, test_prompts, test_labels, \"Base Model\"\n",
    ")\n",
    "\n",
    "# Free memory before loading adapter\n",
    "del model\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ix3dgv0w",
   "metadata": {},
   "source": [
    "## 8. Evaluate GPU-Trained Adapter\n",
    "\n",
    "Download the LoRA adapter trained on RunPod GPU (bfloat16, batch=1, grad_accum=16, 2048 max_length, full dataset) and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "w4hwf0j3yg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/gemma-3-1b-it...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7669e372de4237ad18ad9285defba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPU-trained adapter from abicyclerider/gemma-1b-entity-resolution-lora...\n",
      "\n",
      "Evaluating GPU-trained adapter on 338 test pairs...\n",
      "  50/338...\n",
      "  100/338...\n",
      "  150/338...\n",
      "  200/338...\n",
      "  250/338...\n",
      "  300/338...\n",
      "\n",
      "GPU Fine-Tuned (336 parseable / 338 total):\n",
      "    accuracy: 0.571\n",
      "   precision: 0.544\n",
      "      recall: 0.917\n",
      "          f1: 0.683\n",
      "\n",
      "Confusion matrix (rows=actual, cols=predicted):\n",
      "[[ 37 130]\n",
      " [ 14 155]]\n",
      "\n",
      "    Metric      Base      GPU FT     Delta\n",
      "--------------------------------------------\n",
      "  accuracy     0.527       0.571    +0.045\n",
      " precision     0.523       0.544    +0.021\n",
      "    recall     0.675       0.917    +0.243\n",
      "        f1     0.589       0.683    +0.094\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "GPU_ADAPTER_REPO = \"abicyclerider/gemma-1b-entity-resolution-lora\"\n",
    "\n",
    "print(f\"Loading {MODEL_ID}...\")\n",
    "gpu_base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, dtype=torch.float32, device_map=\"mps\",\n",
    ")\n",
    "\n",
    "print(f\"Loading GPU-trained adapter from {GPU_ADAPTER_REPO}...\")\n",
    "gpu_model = PeftModel.from_pretrained(gpu_base_model, GPU_ADAPTER_REPO)\n",
    "\n",
    "print(f\"\\nEvaluating GPU-trained adapter on {len(test_prompts)} test pairs...\")\n",
    "gpu_metrics, gpu_preds, gpu_labels = run_evaluation(\n",
    "    gpu_model, tokenizer, test_prompts, test_labels, \"GPU Fine-Tuned\"\n",
    ")\n",
    "\n",
    "# Side-by-side comparison\n",
    "print(f\"\\n{'Metric':>10s}  {'Base':>8s}  {'GPU FT':>10s}  {'Delta':>8s}\")\n",
    "print(\"-\" * 44)\n",
    "for m in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    b = base_metrics[m]\n",
    "    gpu = gpu_metrics[m]\n",
    "    print(f\"{m:>10s}  {b:>8.3f}  {gpu:>10.3f}  {gpu-b:>+8.3f}\")\n",
    "\n",
    "# Cleanup\n",
    "del gpu_base_model, gpu_model\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00616edb",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "### Optimize training\n",
    "- **More data**: Use all available pairs instead of capping at 500+500\n",
    "- **Higher LoRA rank**: Try `r=16` or `r=32` for more capacity\n",
    "- **Sequence length**: Current 2048 may truncate some pairs — monitor truncation rate\n",
    "\n",
    "### Larger models\n",
    "- **QLoRA on GPU**: Fine-tune MedGemma 4B or 27B with 4-bit quantization on A100/H100\n",
    "- **MedGemma**: Same architecture as Gemma — same LoRA approach works directly\n",
    "\n",
    "### Integration\n",
    "- Use the fine-tuned model as a **gray zone classifier** in `llm-entity-resolution/src/classify.py`\n",
    "- Replace MedGemma 4B Ollama calls with this faster, local fine-tuned model\n",
    "- Pipeline: demographic blocking → similarity scoring → fine-tuned LLM for ambiguous pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
