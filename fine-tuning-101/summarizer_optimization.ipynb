{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fce82c",
   "metadata": {},
   "source": [
    "# Summarizer Optimization for Entity Resolution\n",
    "\n",
    "Benchmarking from `entity_resolution_fine_tuning.ipynb` revealed the summarizer is the bottleneck:\n",
    "\n",
    "| Format | Tokens (mean) | Accuracy | F1 |\n",
    "|--------|--------------|----------|-----|\n",
    "| Condensed (no dates, names only) | ~200 | 0.620 | 0.558 |\n",
    "| Full `summarize_patient_records()` | ~969 | 0.900 | 0.889 |\n",
    "| Raw records (semantic tags) | ~6069 | 0.980 | 0.980 |\n",
    "\n",
    "The full summarizer loses 9 F1 points vs raw records. This notebook tests 5 summarizer strategies to close that gap while staying within ~500–2000 tokens per summary.\n",
    "\n",
    "**Strategies:**\n",
    "- **A: Temporal-Enhanced** (~1200 tok) — preserve more dates, time-series, encounter details\n",
    "- **B: Identity-Focused** (~600 tok) — only highly discriminative features\n",
    "- **C: Compact Raw** (~2000 tok) — XML-tagged raw records, pruned\n",
    "- **D: Structured Diff-Friendly** (~800 tok) — year-grouped for pairwise comparison\n",
    "- **E: Haiku LLM Summarizer** (~500 tok) — Claude Haiku generates clinical summaries optimized for entity resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b401f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/alex/repos/Kaggle/SyntheticMass\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Add llm-entity-resolution for summarizer imports\n",
    "_llm_er_root = os.path.join(PROJECT_ROOT, \"llm-entity-resolution\")\n",
    "if _llm_er_root not in sys.path:\n",
    "    sys.path.insert(0, _llm_er_root)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count tokens using Gemma tokenizer.\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4c78e",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Pair Generation\n",
    "\n",
    "Reproduce the exact same 50 benchmark pairs (25 match + 25 non-match) from the fine-tuning notebook using the same random seed and pair generation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c35018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True pairs: 1121, Non-match pairs: 1121\n",
      "Test pairs: 100 (50 match + 50 non-match)\n",
      "Benchmark pairs: 50 (25 match + 25 non-match)\n"
     ]
    }
   ],
   "source": [
    "from shared.data_loader import load_facility_patients\n",
    "from shared.ground_truth import (\n",
    "    load_ground_truth,\n",
    "    add_record_ids_to_ground_truth,\n",
    "    generate_true_pairs_from_ground_truth,\n",
    ")\n",
    "from shared.medical_records import load_medical_records, get_patient_records\n",
    "from src.summarize import (\n",
    "    summarize_patient_records,\n",
    "    _summarize_conditions, _summarize_allergies,\n",
    "    _summarize_imaging, _summarize_devices, _summarize_careplans,\n",
    ")\n",
    "\n",
    "RUN_DIR = os.path.join(PROJECT_ROOT, \"output\", \"augmented\", \"run_20260203_071928\")\n",
    "\n",
    "# Load patients and create record_ids\n",
    "patients_df = load_facility_patients(RUN_DIR)\n",
    "patients_df['record_id'] = patients_df['facility_id'] + '_' + patients_df['id'].astype(str)\n",
    "\n",
    "# Load ground truth and add record_ids\n",
    "ground_truth_df = load_ground_truth(RUN_DIR)\n",
    "ground_truth_df = add_record_ids_to_ground_truth(ground_truth_df, patients_df)\n",
    "\n",
    "# Generate true match pairs\n",
    "true_pairs = generate_true_pairs_from_ground_truth(ground_truth_df)\n",
    "\n",
    "# Build record_id -> (patient_uuid, facility_id) mapping\n",
    "record_map = {}\n",
    "for _, row in patients_df.iterrows():\n",
    "    record_map[row['record_id']] = (row['id'], row['facility_id'])\n",
    "\n",
    "# Load medical records\n",
    "medical_records = load_medical_records(RUN_DIR)\n",
    "\n",
    "# Generate non-match pairs (same code + seed as fine-tuning notebook)\n",
    "rid_to_true_id = (ground_truth_df.dropna(subset=['record_id'])\n",
    "                  .set_index('record_id')['true_patient_id'].to_dict())\n",
    "all_record_ids = list(rid_to_true_id.keys())\n",
    "\n",
    "random.seed(42)\n",
    "non_match_pairs = set()\n",
    "target = len(true_pairs)\n",
    "attempts = 0\n",
    "while len(non_match_pairs) < target and attempts < target * 20:\n",
    "    r1, r2 = random.sample(all_record_ids, 2)\n",
    "    if rid_to_true_id.get(r1) != rid_to_true_id.get(r2):\n",
    "        non_match_pairs.add(tuple(sorted([r1, r2])))\n",
    "    attempts += 1\n",
    "\n",
    "# Reproduce train/eval/test split (same as fine-tuning notebook)\n",
    "all_pairs = ([(r1, r2, True) for r1, r2 in true_pairs] +\n",
    "             [(r1, r2, False) for r1, r2 in non_match_pairs])\n",
    "random.shuffle(all_pairs)\n",
    "\n",
    "# Filter to pairs with records (same as fine-tuning notebook filtering by summary_cache)\n",
    "all_pairs = [(r1, r2, l) for r1, r2, l in all_pairs\n",
    "             if r1 in record_map and r2 in record_map]\n",
    "\n",
    "matches = [p for p in all_pairs if p[2]]\n",
    "non_matches = [p for p in all_pairs if not p[2]]\n",
    "\n",
    "n_total = min(len(matches), len(non_matches))\n",
    "n_train = min(500, int(n_total * 0.70))\n",
    "n_eval = min(100, int(n_total * 0.15))\n",
    "n_test = min(50, n_total - n_train - n_eval)\n",
    "\n",
    "test_pairs = (matches[n_train+n_eval:n_train+n_eval+n_test] +\n",
    "              non_matches[n_train+n_eval:n_train+n_eval+n_test])\n",
    "random.shuffle(test_pairs)\n",
    "\n",
    "# Same 50-pair selection as fine-tuning notebook (Sonnet/Opus benchmarks)\n",
    "benchmark_matches = [p for p in test_pairs if p[2]][:25]\n",
    "benchmark_non_matches = [p for p in test_pairs if not p[2]][:25]\n",
    "benchmark_pairs = benchmark_matches + benchmark_non_matches\n",
    "random.shuffle(benchmark_pairs)\n",
    "\n",
    "print(f\"True pairs: {len(true_pairs)}, Non-match pairs: {len(non_match_pairs)}\")\n",
    "print(f\"Test pairs: {len(test_pairs)} ({sum(1 for _,_,l in test_pairs if l)} match + \"\n",
    "      f\"{sum(1 for _,_,l in test_pairs if not l)} non-match)\")\n",
    "print(f\"Benchmark pairs: {len(benchmark_pairs)} \"\n",
    "      f\"({len(benchmark_matches)} match + {len(benchmark_non_matches)} non-match)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a06201",
   "metadata": {},
   "source": [
    "## 2. Shared Benchmark Helpers\n",
    "\n",
    "Reusable `call_opus()` and `run_opus_benchmark()` functions used by all strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1f6dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers loaded. call_opus() and run_opus_benchmark() ready.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from claude_agent_sdk import query, ClaudeAgentOptions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "INSTRUCTION = (\n",
    "    \"You are a medical record matching expert. Compare these two patient \"\n",
    "    \"medical records and determine if they belong to the same patient based \"\n",
    "    \"only on their clinical history.\\n\\n\"\n",
    "    \"Record A:\\n{summary_a}\\n\\n\"\n",
    "    \"Record B:\\n{summary_b}\\n\\n\"\n",
    "    \"Are these the same patient? Answer only 'True' or 'False'.\"\n",
    ")\n",
    "\n",
    "MAX_PAIR_TOKENS = 50_000  # skip pairs exceeding this to avoid context window errors\n",
    "\n",
    "\n",
    "async def call_opus(prompt: str, retries: int = 3) -> str:\n",
    "    \"\"\"Call Claude Opus via claude-agent-sdk with retry on failure.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            result_parts = []\n",
    "            async for message in query(\n",
    "                prompt=prompt,\n",
    "                options=ClaudeAgentOptions(\n",
    "                    model=\"claude-opus-4-6\",\n",
    "                    max_turns=1,\n",
    "                    allowed_tools=[],\n",
    "                    system_prompt=\"You are a medical record matching expert. Answer only 'True' or 'False'.\",\n",
    "                ),\n",
    "            ):\n",
    "                if hasattr(message, 'content'):\n",
    "                    if isinstance(message.content, list):\n",
    "                        for block in message.content:\n",
    "                            if hasattr(block, 'text'):\n",
    "                                result_parts.append(block.text)\n",
    "                    elif isinstance(message.content, str):\n",
    "                        result_parts.append(message.content)\n",
    "            return \"\\n\".join(result_parts)\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                wait = 2 ** (attempt + 1)\n",
    "                print(f\"    Retry {attempt+1}/{retries-1} after error: {e!r} (waiting {wait}s)\")\n",
    "                await asyncio.sleep(wait)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "# Store all results for final comparison\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "async def run_opus_benchmark(name, summarizer_fn, benchmark_pairs, record_map, medical_records):\n",
    "    \"\"\"Run Opus benchmark on 50 pairs with a given summarizer. Returns (metrics, cache).\"\"\"\n",
    "    # Build summary cache\n",
    "    cache = {}\n",
    "    for r1, r2, _ in benchmark_pairs:\n",
    "        for rid in [r1, r2]:\n",
    "            if rid not in cache and rid in record_map:\n",
    "                pid, fid = record_map[rid]\n",
    "                cache[rid] = summarizer_fn(pid, fid, medical_records)\n",
    "\n",
    "    # Token stats\n",
    "    token_lengths = [count_tokens(s) for s in cache.values()]\n",
    "    pair_lengths = [count_tokens(cache[r1]) + count_tokens(cache[r2])\n",
    "                    for r1, r2, _ in benchmark_pairs]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Tokens per summary: mean={np.mean(token_lengths):.0f}, \"\n",
    "          f\"median={np.median(token_lengths):.0f}, max={max(token_lengths)}\")\n",
    "    print(f\"Tokens per pair:    mean={np.mean(pair_lengths):.0f}, max={max(pair_lengths)}\")\n",
    "\n",
    "    # Show example\n",
    "    example_rid = list(cache.keys())[0]\n",
    "    print(f\"\\nExample summary ({example_rid}):\")\n",
    "    print(\"-\" * 40)\n",
    "    text = cache[example_rid]\n",
    "    print(text[:1500])\n",
    "    if len(text) > 1500:\n",
    "        print(\"... (truncated)\")\n",
    "\n",
    "    # Run Opus\n",
    "    print(f\"\\nRunning {len(benchmark_pairs)} pairs through Opus...\")\n",
    "    preds, labels = [], []\n",
    "    skipped, errors = 0, 0\n",
    "    for i, (r1, r2, label) in enumerate(benchmark_pairs):\n",
    "        pair_tok = count_tokens(cache[r1]) + count_tokens(cache[r2])\n",
    "        if pair_tok > MAX_PAIR_TOKENS:\n",
    "            skipped += 1\n",
    "            print(f\"  Pair {i+1}: SKIPPED ({pair_tok:,} tokens exceeds {MAX_PAIR_TOKENS:,} limit)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            prompt = INSTRUCTION.format(summary_a=cache[r1], summary_b=cache[r2])\n",
    "            answer = await call_opus(prompt)\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"  Pair {i+1}: ERROR after retries: {e!r}\")\n",
    "            continue\n",
    "\n",
    "        answer_lower = answer.strip().lower()\n",
    "\n",
    "        if \"true\" in answer_lower:\n",
    "            pred = True\n",
    "        elif \"false\" in answer_lower:\n",
    "            pred = False\n",
    "        else:\n",
    "            print(f\"  Pair {i+1}: unparseable: {answer!r}\")\n",
    "            continue\n",
    "\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            correct = sum(p == l for p, l in zip(preds, labels))\n",
    "            print(f\"  {i+1}/{len(benchmark_pairs)}... ({correct}/{len(preds)} correct)\")\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, zero_division=0),\n",
    "        'recall': recall_score(labels, preds, zero_division=0),\n",
    "        'f1': f1_score(labels, preds, zero_division=0),\n",
    "        'tokens_mean': np.mean(token_lengths),\n",
    "        'tokens_pair_mean': np.mean(pair_lengths),\n",
    "    }\n",
    "\n",
    "    print(f\"\\nResults ({len(preds)} scored / {skipped} skipped / {errors} errors \"\n",
    "          f\"/ {len(benchmark_pairs)} total):\")\n",
    "    for m in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        print(f\"  {m:>10s}: {metrics[m]:.3f}\")\n",
    "    print(f\"\\nConfusion Matrix (rows=actual, cols=predicted):\")\n",
    "    print(confusion_matrix(labels, preds))\n",
    "\n",
    "    all_results[name] = metrics\n",
    "    return metrics, cache\n",
    "\n",
    "\n",
    "print(\"Helpers loaded. call_opus() and run_opus_benchmark() ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c39ab6",
   "metadata": {},
   "source": [
    "## 3. Baseline: Full Summary (`summarize_patient_records`)\n",
    "\n",
    "Re-run the production summarizer as a live baseline on the same 50 pairs.\n",
    "Known result from fine-tuning notebook: accuracy=0.900, F1=0.889."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ecc149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Baseline (full summary)\n",
      "============================================================\n",
      "Tokens per summary: mean=1019, median=992, max=2624\n",
      "Tokens per pair:    mean=2048, max=3845\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "=== MEDICAL HISTORY ===\n",
      "\n",
      "CONDITIONS (active/historical):\n",
      "- Received certificate of high school equivalency (finding) (onset: 1978-11-15, ongoing)\n",
      "- Stress (finding) (x9) (onset: 1978-11-15, resolved 2018-05-30)\n",
      "- Part-time employment (finding) (x8) (onset: 1982-11-24, resolved 2016-05-18)\n",
      "- Essential hypertension (disorder) (onset: 1985-11-27, ongoing)\n",
      "- Miscarriage in first trimester (onset: 1989-05-10, ongoing)\n",
      "- Body mass index 30+ - obesity (finding) (onset: 1993-01-06, ongoing)\n",
      "- Unhealthy alcohol drinking behavior (finding) (onset: 1993-01-06, resolved 1999-02-10)\n",
      "- History of tubal ligation (situation) (onset: 1996-06-21, ongoing)\n",
      "- Victim of intimate partner abuse (finding) (onset: 2011-04-20, resolved 2016-05-18)\n",
      "\n",
      "MEDICATIONS (current/past):\n",
      "- Hydrochlorothiazide 25 MG Oral Tablet (1985-11-27 to 2016-05-18) for Essential hypertension (disorder) (x32 fills)\n",
      "- lisinopril 10 MG Oral Tablet (1985-11-27 to 2016-05-18) for Essential hypertension (disorder) (x32 fills)\n",
      "- ferrous sulfate 325 MG Oral Tablet (1986-12-10 to present)\n",
      "\n",
      "ENCOUNTERS (summarized):\n",
      "- 32 wellness visits (1978-2015)\n",
      "- 2 ambulatory visits (1986-1989)\n",
      "- 1 outpatient visits (1991-1991)\n",
      "- 1 inpatient visits (1996-1996)\n",
      "Recent:\n",
      "  - 2015-05-13 wellness\n",
      "  - 2014-05-07 wellness\n",
      "  - 2013-05-01 wellness\n",
      "\n",
      "KEY OBSERVATIONS: none\n",
      "\n",
      "PROCEDURES: none\n",
      "\n",
      "IMMUNIZATIONS: none\n",
      "\n",
      "ALLERGIES: none\n",
      "\n",
      "IMAGING: none\n",
      "\n",
      "DEVICES: none\n",
      "\n",
      "CARE PLANS: Lifestyle education regarding hypertension\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (20/20 correct)\n",
      "  30/50... (29/30 correct)\n",
      "  40/50... (39/40 correct)\n",
      "  50/50... (47/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.940\n",
      "   precision: 1.000\n",
      "      recall: 0.880\n",
      "          f1: 0.936\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[25  0]\n",
      " [ 3 22]]\n"
     ]
    }
   ],
   "source": [
    "baseline_metrics, baseline_cache = await run_opus_benchmark(\n",
    "    \"Baseline (full summary)\",\n",
    "    summarize_patient_records,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676afb7d",
   "metadata": {},
   "source": [
    "## 4. Strategy A: Temporal-Enhanced (~1200 tokens)\n",
    "\n",
    "Preserve more temporal detail than the production summarizer:\n",
    "- **Conditions**: Same as production (already has onset dates + status)\n",
    "- **Medications**: Individual fill start dates per drug (not just \"first to last\" range)\n",
    "- **Observations**: Last 3 values per key metric (not just latest) to reveal trends\n",
    "- **Procedures**: All procedures with all dates (no top-15 cutoff)\n",
    "- **Encounters**: One-liner per encounter with date + class + reason\n",
    "- **Immunizations**: Each with individual date (not just counts)\n",
    "- **Allergies/Imaging/Devices/Careplans**: Same as production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce403c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize_temporal_enhanced() defined.\n"
     ]
    }
   ],
   "source": [
    "def summarize_temporal_enhanced(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Enhanced summary preserving temporal detail. Target ~1200 tokens.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = [\"=== MEDICAL HISTORY ===\"]\n",
    "\n",
    "    # CONDITIONS - reuse production (already includes onset dates + status)\n",
    "    conditions_df = records.get('conditions')\n",
    "    sections.append(_summarize_conditions(conditions_df))\n",
    "\n",
    "    # MEDICATIONS - individual fill start dates per drug\n",
    "    meds_df = records.get('medications')\n",
    "    if meds_df is not None:\n",
    "        meds_df = meds_df.copy().sort_values('START')\n",
    "        lines = [\"MEDICATIONS:\"]\n",
    "        for desc, grp in meds_df.groupby('DESCRIPTION', sort=False):\n",
    "            dates = sorted(grp['START'].astype(str).str[:10].unique())\n",
    "            reasons = grp['REASONDESCRIPTION'].dropna()\n",
    "            reasons = reasons[reasons.astype(str).str.strip() != '']\n",
    "            reason = reasons.mode().iloc[0] if not reasons.empty else \"\"\n",
    "            reason_str = f\" for {reason}\" if reason else \"\"\n",
    "            is_current = grp['STOP'].isna().any() | (grp['STOP'].astype(str).str.strip() == '').any()\n",
    "            status = \" (ongoing)\" if is_current else \"\"\n",
    "            lines.append(f\"- {desc}: {', '.join(dates)}{reason_str}{status}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "    else:\n",
    "        sections.append(\"MEDICATIONS: none\")\n",
    "\n",
    "    # ENCOUNTERS - one-liner per encounter\n",
    "    enc_df = records.get('encounters')\n",
    "    if enc_df is not None:\n",
    "        enc_df = enc_df.copy().sort_values('START')\n",
    "        lines = [\"ENCOUNTERS:\"]\n",
    "        for _, row in enc_df.iterrows():\n",
    "            date = str(row.get('START', ''))[:10]\n",
    "            enc_class = row.get('ENCOUNTERCLASS', '')\n",
    "            reason = row.get('REASONDESCRIPTION', '')\n",
    "            reason_str = f\" \\u2014 {reason}\" if pd.notna(reason) and str(reason).strip() else \"\"\n",
    "            lines.append(f\"- {date} {enc_class}{reason_str}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "    else:\n",
    "        sections.append(\"ENCOUNTERS: none\")\n",
    "\n",
    "    # OBSERVATIONS - last 3 values per key metric\n",
    "    obs_df = records.get('observations')\n",
    "    if obs_df is not None:\n",
    "        obs_df = obs_df.copy()\n",
    "        obs_df['date_dt'] = pd.to_datetime(obs_df['DATE'], errors='coerce')\n",
    "        key_obs = [\n",
    "            'Body Height', 'Body Weight', 'Body Mass Index',\n",
    "            'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
    "            'Hemoglobin A1c/Hemoglobin.total in Blood',\n",
    "            'Glucose', 'Total Cholesterol',\n",
    "            'Heart rate', 'Respiratory rate',\n",
    "            'Estimated Glomerular Filtration Rate',\n",
    "        ]\n",
    "        lines = [\"KEY OBSERVATIONS (last 3 values):\"]\n",
    "        for obs_name in key_obs:\n",
    "            match = obs_df[obs_df['DESCRIPTION'].str.contains(obs_name, case=False, na=False)]\n",
    "            if match.empty:\n",
    "                continue\n",
    "            recent = match.sort_values('date_dt').tail(3)\n",
    "            vals = []\n",
    "            for _, row in recent.iterrows():\n",
    "                v = row.get('VALUE', '')\n",
    "                u = row.get('UNITS', '')\n",
    "                d = str(row.get('DATE', ''))[:10]\n",
    "                if pd.notna(v) and str(v).strip():\n",
    "                    u_str = f\" {u}\" if pd.notna(u) and u else \"\"\n",
    "                    vals.append(f\"{v}{u_str} ({d})\")\n",
    "            if vals:\n",
    "                lines.append(f\"- {obs_name}: {' \\u2192 '.join(vals)}\")\n",
    "        lines.append(f\"- Total observations on file: {len(obs_df)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "    else:\n",
    "        sections.append(\"KEY OBSERVATIONS: none\")\n",
    "\n",
    "    # PROCEDURES - all with dates (no top-15 cutoff)\n",
    "    proc_df = records.get('procedures')\n",
    "    if proc_df is not None:\n",
    "        proc_df = proc_df.copy().sort_values('START')\n",
    "        lines = [\"PROCEDURES:\"]\n",
    "        for desc, grp in proc_df.groupby('DESCRIPTION', sort=False):\n",
    "            dates = sorted(grp['START'].astype(str).str[:10].unique())\n",
    "            lines.append(f\"- {desc}: {', '.join(dates)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "    else:\n",
    "        sections.append(\"PROCEDURES: none\")\n",
    "\n",
    "    # IMMUNIZATIONS - each with date\n",
    "    imm_df = records.get('immunizations')\n",
    "    if imm_df is not None:\n",
    "        imm_df = imm_df.copy().sort_values('DATE')\n",
    "        lines = [\"IMMUNIZATIONS:\"]\n",
    "        for _, row in imm_df.iterrows():\n",
    "            date = str(row.get('DATE', ''))[:10]\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            lines.append(f\"- {date}: {desc}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "    else:\n",
    "        sections.append(\"IMMUNIZATIONS: none\")\n",
    "\n",
    "    # ALLERGIES, IMAGING, DEVICES, CAREPLANS - reuse production\n",
    "    sections.append(_summarize_allergies(records.get('allergies')))\n",
    "    sections.append(_summarize_imaging(records.get('imaging_studies')))\n",
    "    sections.append(_summarize_devices(records.get('devices')))\n",
    "    sections.append(_summarize_careplans(records.get('careplans')))\n",
    "\n",
    "    return \"\\n\\n\".join(s for s in sections if s)\n",
    "\n",
    "\n",
    "print(\"summarize_temporal_enhanced() defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d688ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  A: Temporal-Enhanced\n",
      "============================================================\n",
      "Tokens per summary: mean=2315, median=1601, max=12148\n",
      "Tokens per pair:    mean=4564, max=14439\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "=== MEDICAL HISTORY ===\n",
      "\n",
      "CONDITIONS (active/historical):\n",
      "- Received certificate of high school equivalency (finding) (onset: 1978-11-15, ongoing)\n",
      "- Stress (finding) (x9) (onset: 1978-11-15, resolved 2018-05-30)\n",
      "- Part-time employment (finding) (x8) (onset: 1982-11-24, resolved 2016-05-18)\n",
      "- Essential hypertension (disorder) (onset: 1985-11-27, ongoing)\n",
      "- Miscarriage in first trimester (onset: 1989-05-10, ongoing)\n",
      "- Body mass index 30+ - obesity (finding) (onset: 1993-01-06, ongoing)\n",
      "- Unhealthy alcohol drinking behavior (finding) (onset: 1993-01-06, resolved 1999-02-10)\n",
      "- History of tubal ligation (situation) (onset: 1996-06-21, ongoing)\n",
      "- Victim of intimate partner abuse (finding) (onset: 2011-04-20, resolved 2016-05-18)\n",
      "\n",
      "MEDICATIONS:\n",
      "- Hydrochlorothiazide 25 MG Oral Tablet: 1985-11-27, 1986-12-03, 1987-12-09, 1988-12-14, 1989-12-20, 1990-12-26, 1991-07-24, 1992-01-01, 1993-01-06, 1994-01-12, 1995-01-18, 1996-01-24, 1997-01-29, 1998-02-04, 1999-02-10, 2000-02-16, 2001-02-21, 2002-02-27, 2003-03-05, 2004-03-10, 2005-03-16, 2006-03-22, 2007-03-28, 2008-04-02, 2009-04-08, 2010-04-14, 2011-04-20, 2012-04-25, 2013-05-01, 2014-05-07, 2015-05-13 for Essential hypertension (disorder)\n",
      "- lisinopril 10 MG Oral Tablet: 1985-11-27, 1986-12-03, 1987-12-09, 1988-12-14, 1989-12-20, 1990-12-26, 1991-07-24, 1992-01-01, 1993-01-06, 1994-01-12, 1995-01-18, 1996-01-24, 1997-01-29, 1998-02-04, 1999-02-10, 2000-02-16, 2001-02-21, 2002-02-27, 2003-03-05, 2004-03-10, 2005-03-16, 2006-03-22, 2007-03-\n",
      "... (truncated)\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (20/20 correct)\n",
      "  30/50... (29/30 correct)\n",
      "  40/50... (39/40 correct)\n",
      "  50/50... (47/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.940\n",
      "   precision: 1.000\n",
      "      recall: 0.880\n",
      "          f1: 0.936\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[25  0]\n",
      " [ 3 22]]\n"
     ]
    }
   ],
   "source": [
    "strategy_a_metrics, strategy_a_cache = await run_opus_benchmark(\n",
    "    \"A: Temporal-Enhanced\",\n",
    "    summarize_temporal_enhanced,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820653a",
   "metadata": {},
   "source": [
    "## 5. Strategy B: Identity-Focused (~600 tokens)\n",
    "\n",
    "Only the most discriminative features for patient matching:\n",
    "- **Chronic conditions only** — filter out resolved conditions and generic social/employment findings\n",
    "- **All medications** with dosages (discriminative)\n",
    "- **All allergies** (rare and highly patient-specific)\n",
    "- **Key stable vitals**: height, weight, BMI (stable identifiers)\n",
    "- **Rare procedures** only — skip routine screenings (depression, anxiety, substance use assessments)\n",
    "- **Skip**: encounters, immunizations, care plans, devices, imaging (low signal-to-noise for matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e34fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize_identity_focused() defined.\n"
     ]
    }
   ],
   "source": [
    "# Generic conditions that appear on many patients (low discriminative value)\n",
    "GENERIC_CONDITIONS = {\n",
    "    'Medication review due (situation)',\n",
    "    'Full-time employment (finding)',\n",
    "    'Part-time employment (finding)',\n",
    "    'Unemployed (finding)',\n",
    "    'Not in labor force (finding)',\n",
    "    'Received higher education (finding)',\n",
    "    'Only received primary school education (finding)',\n",
    "    'Received certificate of high school equivalency (finding)',\n",
    "    'Social isolation (finding)',\n",
    "    'Limited social contact (finding)',\n",
    "    'Reports of violence in the environment (finding)',\n",
    "    'Stress (finding)',\n",
    "    'Victim of intimate partner abuse (finding)',\n",
    "}\n",
    "\n",
    "# Common screening procedures (appear on nearly every patient)\n",
    "COMMON_SCREENING_PROCEDURES = {\n",
    "    'Assessment of health and social care needs (procedure)',\n",
    "    'Assessment of anxiety (procedure)',\n",
    "    'Assessment of substance use (procedure)',\n",
    "    'Depression screening (procedure)',\n",
    "    'Depression screening using Patient Health Questionnaire Nine Item score (procedure)',\n",
    "    'Depression screening using Patient Health Questionnaire Two-Item score (procedure)',\n",
    "    'Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure)',\n",
    "    'Medication Reconciliation (procedure)',\n",
    "    'Screening for domestic abuse (procedure)',\n",
    "    'Screening for drug abuse (procedure)',\n",
    "}\n",
    "\n",
    "\n",
    "def summarize_identity_focused(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Identity-focused summary with only discriminative features. Target ~600 tokens.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = []\n",
    "\n",
    "    # CHRONIC CONDITIONS (ongoing only, skip generic)\n",
    "    cond_df = records.get('conditions')\n",
    "    if cond_df is not None:\n",
    "        cond_df = cond_df.copy()\n",
    "        cond_df['is_ongoing'] = cond_df['STOP'].isna() | (cond_df['STOP'].astype(str).str.strip() == '')\n",
    "        chronic = cond_df[cond_df['is_ongoing']]\n",
    "        chronic = chronic[~chronic['DESCRIPTION'].isin(GENERIC_CONDITIONS)]\n",
    "        if not chronic.empty:\n",
    "            names = sorted(chronic['DESCRIPTION'].unique())\n",
    "            sections.append(\"CHRONIC CONDITIONS: \" + \"; \".join(names))\n",
    "\n",
    "    # ALL MEDICATIONS (with dosages — discriminative)\n",
    "    meds_df = records.get('medications')\n",
    "    if meds_df is not None:\n",
    "        names = sorted(meds_df['DESCRIPTION'].unique())\n",
    "        sections.append(\"MEDICATIONS: \" + \"; \".join(names))\n",
    "\n",
    "    # ALLERGIES (rare and patient-specific)\n",
    "    allg_df = records.get('allergies')\n",
    "    if allg_df is not None:\n",
    "        lines = []\n",
    "        for _, row in allg_df.iterrows():\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            reaction = row.get('DESCRIPTION1', '')\n",
    "            extras = []\n",
    "            if pd.notna(reaction) and str(reaction).strip():\n",
    "                extras.append(str(reaction))\n",
    "            extra_str = f\" ({', '.join(extras)})\" if extras else \"\"\n",
    "            lines.append(f\"{desc}{extra_str}\")\n",
    "        sections.append(\"ALLERGIES: \" + \"; \".join(lines))\n",
    "\n",
    "    # KEY STABLE VITALS (height, weight, BMI)\n",
    "    obs_df = records.get('observations')\n",
    "    if obs_df is not None:\n",
    "        obs_df = obs_df.copy()\n",
    "        obs_df['date_dt'] = pd.to_datetime(obs_df['DATE'], errors='coerce')\n",
    "        stable_metrics = ['Body Height', 'Body Weight', 'Body Mass Index']\n",
    "        vitals = []\n",
    "        for metric in stable_metrics:\n",
    "            match = obs_df[obs_df['DESCRIPTION'].str.contains(metric, case=False, na=False)]\n",
    "            if not match.empty:\n",
    "                latest = match.sort_values('date_dt').iloc[-1]\n",
    "                v = latest.get('VALUE', '')\n",
    "                u = latest.get('UNITS', '')\n",
    "                if pd.notna(v) and str(v).strip():\n",
    "                    u_str = f\" {u}\" if pd.notna(u) and u else \"\"\n",
    "                    vitals.append(f\"{metric}: {v}{u_str}\")\n",
    "        if vitals:\n",
    "            sections.append(\"VITALS: \" + \"; \".join(vitals))\n",
    "\n",
    "    # RARE PROCEDURES (not common screenings)\n",
    "    proc_df = records.get('procedures')\n",
    "    if proc_df is not None:\n",
    "        rare = proc_df[~proc_df['DESCRIPTION'].isin(COMMON_SCREENING_PROCEDURES)]\n",
    "        if not rare.empty:\n",
    "            names = sorted(rare['DESCRIPTION'].unique())[:20]\n",
    "            sections.append(\"PROCEDURES: \" + \"; \".join(names))\n",
    "\n",
    "    return \"\\n\".join(sections) if sections else \"No clinical records available.\"\n",
    "\n",
    "\n",
    "print(\"summarize_identity_focused() defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86bbf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  B: Identity-Focused\n",
      "============================================================\n",
      "Tokens per summary: mean=145, median=125, max=568\n",
      "Tokens per pair:    mean=288, max=703\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "CHRONIC CONDITIONS: Body mass index 30+ - obesity (finding); Essential hypertension (disorder); History of tubal ligation (situation); Miscarriage in first trimester\n",
      "MEDICATIONS: Hydrochlorothiazide 25 MG Oral Tablet; ferrous sulfate 325 MG Oral Tablet; lisinopril 10 MG Oral Tablet\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (19/20 correct)\n",
      "  30/50... (27/30 correct)\n",
      "  40/50... (37/40 correct)\n",
      "  50/50... (46/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.920\n",
      "   precision: 0.957\n",
      "      recall: 0.880\n",
      "          f1: 0.917\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[24  1]\n",
      " [ 3 22]]\n"
     ]
    }
   ],
   "source": [
    "strategy_b_metrics, strategy_b_cache = await run_opus_benchmark(\n",
    "    \"B: Identity-Focused\",\n",
    "    summarize_identity_focused,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc8c",
   "metadata": {},
   "source": [
    "## 6. Strategy C: Compact Raw (~2000 tokens)\n",
    "\n",
    "Raw records format with semantic XML tags but aggressively pruned:\n",
    "- **Keep**: conditions, medications, allergies, procedures, key observations\n",
    "- **Drop**: encounters (noisy), care plans, devices, supplies, imaging\n",
    "- **Observations**: filtered to discriminative types (chronic disease markers, not routine vitals)\n",
    "- **Each section** capped at 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291dd2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize_compact_raw() defined.\n"
     ]
    }
   ],
   "source": [
    "# Observation types that are discriminative for patient matching\n",
    "DISCRIMINATIVE_OBS = [\n",
    "    'Body Height', 'Body Weight', 'Body Mass Index',\n",
    "    'Hemoglobin A1c', 'Glucose', 'Total Cholesterol',\n",
    "    'Triglycerides', 'Low Density', 'High Density',\n",
    "    'Creatinine', 'Estimated Glomerular Filtration Rate',\n",
    "    'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
    "    'Calcium', 'Sodium', 'Potassium', 'Chloride',\n",
    "    'Carbon Dioxide', 'Urea Nitrogen',\n",
    "]\n",
    "\n",
    "SECTION_CAP = 30  # max rows per section to prevent runaway summaries\n",
    "\n",
    "\n",
    "def summarize_compact_raw(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Compact raw records with XML tags. Target ~2000 tokens.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = []\n",
    "\n",
    "    # Conditions (cap at SECTION_CAP)\n",
    "    cond_df = records.get('conditions')\n",
    "    if cond_df is not None:\n",
    "        cond_df = cond_df.sort_values('START')\n",
    "        lines = [\"<conditions>\"]\n",
    "        for _, row in cond_df.head(SECTION_CAP).iterrows():\n",
    "            start = str(row.get('START', ''))[:10]\n",
    "            stop_val = row.get('STOP')\n",
    "            stop = str(stop_val)[:10] if pd.notna(stop_val) and str(stop_val).strip() else 'ongoing'\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            lines.append(f\"  {start} to {stop}: {desc}\")\n",
    "        if len(cond_df) > SECTION_CAP:\n",
    "            lines.append(f\"  ... and {len(cond_df) - SECTION_CAP} more\")\n",
    "        lines.append(\"</conditions>\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # Medications (cap at SECTION_CAP)\n",
    "    meds_df = records.get('medications')\n",
    "    if meds_df is not None:\n",
    "        meds_df = meds_df.sort_values('START')\n",
    "        lines = [\"<medications>\"]\n",
    "        for _, row in meds_df.head(SECTION_CAP).iterrows():\n",
    "            start = str(row.get('START', ''))[:10]\n",
    "            stop_val = row.get('STOP')\n",
    "            stop = str(stop_val)[:10] if pd.notna(stop_val) and str(stop_val).strip() else 'ongoing'\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            reason = row.get('REASONDESCRIPTION', '')\n",
    "            reason_str = f\" for {reason}\" if pd.notna(reason) and str(reason).strip() else \"\"\n",
    "            lines.append(f\"  {start} to {stop}: {desc}{reason_str}\")\n",
    "        if len(meds_df) > SECTION_CAP:\n",
    "            lines.append(f\"  ... and {len(meds_df) - SECTION_CAP} more\")\n",
    "        lines.append(\"</medications>\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # Allergies (cap at SECTION_CAP)\n",
    "    allg_df = records.get('allergies')\n",
    "    if allg_df is not None:\n",
    "        lines = [\"<allergies>\"]\n",
    "        for _, row in allg_df.head(SECTION_CAP).iterrows():\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            reaction = row.get('DESCRIPTION1', '')\n",
    "            severity = row.get('SEVERITY1', '')\n",
    "            extras = []\n",
    "            if pd.notna(reaction) and str(reaction).strip():\n",
    "                extras.append(str(reaction))\n",
    "            if pd.notna(severity) and str(severity).strip():\n",
    "                extras.append(str(severity))\n",
    "            extra_str = f\" ({', '.join(extras)})\" if extras else \"\"\n",
    "            lines.append(f\"  {desc}{extra_str}\")\n",
    "        if len(allg_df) > SECTION_CAP:\n",
    "            lines.append(f\"  ... and {len(allg_df) - SECTION_CAP} more\")\n",
    "        lines.append(\"</allergies>\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # Procedures (cap at SECTION_CAP)\n",
    "    proc_df = records.get('procedures')\n",
    "    if proc_df is not None:\n",
    "        proc_df = proc_df.sort_values('START')\n",
    "        lines = [\"<procedures>\"]\n",
    "        for _, row in proc_df.head(SECTION_CAP).iterrows():\n",
    "            start = str(row.get('START', ''))[:10]\n",
    "            desc = row.get('DESCRIPTION', '')\n",
    "            lines.append(f\"  {start}: {desc}\")\n",
    "        if len(proc_df) > SECTION_CAP:\n",
    "            lines.append(f\"  ... and {len(proc_df) - SECTION_CAP} more\")\n",
    "        lines.append(\"</procedures>\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # Observations - discriminative types only (cap at SECTION_CAP)\n",
    "    obs_df = records.get('observations')\n",
    "    if obs_df is not None:\n",
    "        mask = obs_df['DESCRIPTION'].apply(\n",
    "            lambda d: any(k in str(d) for k in DISCRIMINATIVE_OBS) if pd.notna(d) else False\n",
    "        )\n",
    "        filtered = obs_df[mask].sort_values('DATE')\n",
    "        if not filtered.empty:\n",
    "            lines = [\"<observations>\"]\n",
    "            for _, row in filtered.tail(SECTION_CAP).iterrows():\n",
    "                date = str(row.get('DATE', ''))[:10]\n",
    "                desc = row.get('DESCRIPTION', '')\n",
    "                val = row.get('VALUE', '')\n",
    "                units = row.get('UNITS', '')\n",
    "                u_str = f\" {units}\" if pd.notna(units) and str(units).strip() else \"\"\n",
    "                lines.append(f\"  {date}: {desc} = {val}{u_str}\")\n",
    "            if len(filtered) > SECTION_CAP:\n",
    "                lines.append(f\"  ... and {len(filtered) - SECTION_CAP} more\")\n",
    "            lines.append(\"</observations>\")\n",
    "            sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    return \"\\n\\n\".join(sections) if sections else \"No clinical records available.\"\n",
    "\n",
    "\n",
    "print(\"summarize_compact_raw() defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe8aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  C: Compact Raw\n",
      "============================================================\n",
      "Tokens per summary: mean=1846, median=1709, max=4322\n",
      "Tokens per pair:    mean=3694, max=8561\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "<conditions>\n",
      "  1978-11-15 to ongoing: Received certificate of high school equivalency (finding)\n",
      "  1978-11-15 to 1979-11-21: Stress (finding)\n",
      "  1982-11-24 to 1985-11-27: Part-time employment (finding)\n",
      "  1982-11-24 to 1985-11-27: Stress (finding)\n",
      "  1985-11-27 to ongoing: Essential hypertension (disorder)\n",
      "  1988-12-14 to 1997-01-29: Stress (finding)\n",
      "  1989-05-10 to ongoing: Miscarriage in first trimester\n",
      "  1990-12-26 to 1991-07-24: Part-time employment (finding)\n",
      "  1993-01-06 to ongoing: Body mass index 30+ - obesity (finding)\n",
      "  1993-01-06 to 1999-02-10: Unhealthy alcohol drinking behavior (finding)\n",
      "  1995-01-18 to 1996-01-24: Part-time employment (finding)\n",
      "  1996-06-21 to ongoing: History of tubal ligation (situation)\n",
      "  1997-01-29 to 1998-02-04: Part-time employment (finding)\n",
      "  1998-02-04 to 2000-02-16: Stress (finding)\n",
      "  1999-02-10 to 2000-02-16: Part-time employment (finding)\n",
      "  2001-02-21 to 2002-02-27: Stress (finding)\n",
      "  2002-02-27 to 2003-03-05: Part-time employment (finding)\n",
      "  2003-03-05 to 2004-03-10: Stress (finding)\n",
      "  2005-03-16 to 2009-04-08: Stress (finding)\n",
      "  2006-03-22 to 2007-03-28: Part-time employment (finding)\n",
      "  2010-04-14 to 2012-04-25: Stress (finding)\n",
      "  2011-04-20 to 2016-05-18: Victim of intimate partner abuse (finding)\n",
      "  2013-05-01 to 2018-05-30: Stress (finding)\n",
      "  2015-05-13 to 2016-05-18: Part-time employment (finding)\n",
      "</conditions>\n",
      "\n",
      "<medications>\n",
      "  1985-11-27 to 1985-11-27: Hydrochlorothiazide 25 MG Oral Tablet for Essential hypertension (disorder)\n",
      "  1985\n",
      "... (truncated)\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (20/20 correct)\n",
      "  30/50... (28/30 correct)\n",
      "  40/50... (38/40 correct)\n",
      "  50/50... (46/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.920\n",
      "   precision: 1.000\n",
      "      recall: 0.840\n",
      "          f1: 0.913\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[25  0]\n",
      " [ 4 21]]\n"
     ]
    }
   ],
   "source": [
    "strategy_c_metrics, strategy_c_cache = await run_opus_benchmark(\n",
    "    \"C: Compact Raw\",\n",
    "    summarize_compact_raw,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230dc77c",
   "metadata": {},
   "source": [
    "## 7. Strategy D: Structured Diff-Friendly (~800 tokens)\n",
    "\n",
    "Designed specifically for pairwise comparison — organized by clinical category with year grouping:\n",
    "- **Conditions** grouped by onset year (e.g., \"2014: hypertension, prediabetes; 2019: obesity\")\n",
    "- **Medications** as \"drug (start_year–end_year or ongoing)\"\n",
    "- **Allergies** as flat list\n",
    "- **Key observations**: latest 2 values per metric\n",
    "- **Procedures** with years, sorted chronologically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5c4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize_diff_friendly() defined.\n"
     ]
    }
   ],
   "source": [
    "def summarize_diff_friendly(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Structured for pairwise comparison, grouped by year. Target ~800 tokens.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = []\n",
    "\n",
    "    # CONDITIONS - grouped by onset year\n",
    "    cond_df = records.get('conditions')\n",
    "    if cond_df is not None:\n",
    "        cond_df = cond_df.copy()\n",
    "        cond_df['year'] = pd.to_datetime(cond_df['START'], errors='coerce').dt.year\n",
    "        cond_df['is_ongoing'] = cond_df['STOP'].isna() | (cond_df['STOP'].astype(str).str.strip() == '')\n",
    "        lines = [\"CONDITIONS:\"]\n",
    "        for year, grp in sorted(cond_df.groupby('year')):\n",
    "            if pd.isna(year):\n",
    "                continue\n",
    "            descs = []\n",
    "            for _, row in grp.iterrows():\n",
    "                status = \" *\" if row['is_ongoing'] else \"\"\n",
    "                descs.append(f\"{row['DESCRIPTION']}{status}\")\n",
    "            lines.append(f\"  {int(year)}: {'; '.join(descs)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # MEDICATIONS - drug (start_year-end_year or ongoing)\n",
    "    meds_df = records.get('medications')\n",
    "    if meds_df is not None:\n",
    "        meds_df = meds_df.copy()\n",
    "        lines = [\"MEDICATIONS:\"]\n",
    "        for desc, grp in meds_df.groupby('DESCRIPTION', sort=False):\n",
    "            start_dt = pd.to_datetime(grp['START'], errors='coerce').min()\n",
    "            is_current = grp['STOP'].isna().any() | (grp['STOP'].astype(str).str.strip() == '').any()\n",
    "            if is_current:\n",
    "                period = f\"{start_dt.year}\\u2013ongoing\" if pd.notna(start_dt) else \"ongoing\"\n",
    "            else:\n",
    "                end_dt = pd.to_datetime(grp['STOP'], errors='coerce').max()\n",
    "                if pd.notna(start_dt) and pd.notna(end_dt):\n",
    "                    period = f\"{start_dt.year}\\u2013{end_dt.year}\"\n",
    "                else:\n",
    "                    period = \"unknown\"\n",
    "            lines.append(f\"- {desc} ({period})\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # ALLERGIES - flat list\n",
    "    allg_df = records.get('allergies')\n",
    "    if allg_df is not None:\n",
    "        names = sorted(allg_df['DESCRIPTION'].unique())\n",
    "        sections.append(\"ALLERGIES: \" + \"; \".join(names))\n",
    "\n",
    "    # KEY OBSERVATIONS - latest 2 values per metric\n",
    "    obs_df = records.get('observations')\n",
    "    if obs_df is not None:\n",
    "        obs_df = obs_df.copy()\n",
    "        obs_df['date_dt'] = pd.to_datetime(obs_df['DATE'], errors='coerce')\n",
    "        key_obs = [\n",
    "            'Body Height', 'Body Weight', 'Body Mass Index',\n",
    "            'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
    "            'Hemoglobin A1c/Hemoglobin.total in Blood',\n",
    "            'Glucose', 'Total Cholesterol',\n",
    "        ]\n",
    "        lines = [\"OBSERVATIONS:\"]\n",
    "        for obs_name in key_obs:\n",
    "            match = obs_df[obs_df['DESCRIPTION'].str.contains(obs_name, case=False, na=False)]\n",
    "            if match.empty:\n",
    "                continue\n",
    "            recent = match.sort_values('date_dt').tail(2)\n",
    "            vals = []\n",
    "            for _, row in recent.iterrows():\n",
    "                v = row.get('VALUE', '')\n",
    "                u = row.get('UNITS', '')\n",
    "                d = str(row.get('DATE', ''))[:10]\n",
    "                if pd.notna(v) and str(v).strip():\n",
    "                    u_str = f\" {u}\" if pd.notna(u) and u else \"\"\n",
    "                    vals.append(f\"{v}{u_str} ({d})\")\n",
    "            if vals:\n",
    "                lines.append(f\"- {obs_name}: {', '.join(vals)}\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    # PROCEDURES - with years, chronological\n",
    "    proc_df = records.get('procedures')\n",
    "    if proc_df is not None:\n",
    "        proc_df = proc_df.copy()\n",
    "        proc_df['year'] = pd.to_datetime(proc_df['START'], errors='coerce').dt.year\n",
    "        lines = [\"PROCEDURES:\"]\n",
    "        for desc, grp in proc_df.groupby('DESCRIPTION', sort=False):\n",
    "            years = sorted(grp['year'].dropna().unique())\n",
    "            year_strs = [str(int(y)) for y in years]\n",
    "            lines.append(f\"- {desc} ({', '.join(year_strs)})\")\n",
    "        sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    return \"\\n\\n\".join(sections) if sections else \"No clinical records available.\"\n",
    "\n",
    "\n",
    "print(\"summarize_diff_friendly() defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "204b5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  D: Structured Diff-Friendly\n",
      "============================================================\n",
      "Tokens per summary: mean=760, median=627, max=2154\n",
      "Tokens per pair:    mean=1508, max=3366\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "CONDITIONS:\n",
      "  1978: Received certificate of high school equivalency (finding) *; Stress (finding)\n",
      "  1982: Part-time employment (finding); Stress (finding)\n",
      "  1985: Essential hypertension (disorder) *\n",
      "  1988: Stress (finding)\n",
      "  1989: Miscarriage in first trimester *\n",
      "  1990: Part-time employment (finding)\n",
      "  1993: Body mass index 30+ - obesity (finding) *; Unhealthy alcohol drinking behavior (finding)\n",
      "  1995: Part-time employment (finding)\n",
      "  1996: History of tubal ligation (situation) *\n",
      "  1997: Part-time employment (finding)\n",
      "  1998: Stress (finding)\n",
      "  1999: Part-time employment (finding)\n",
      "  2001: Stress (finding)\n",
      "  2002: Part-time employment (finding)\n",
      "  2003: Stress (finding)\n",
      "  2005: Stress (finding)\n",
      "  2006: Part-time employment (finding)\n",
      "  2010: Stress (finding)\n",
      "  2011: Victim of intimate partner abuse (finding)\n",
      "  2013: Stress (finding)\n",
      "  2015: Part-time employment (finding)\n",
      "\n",
      "MEDICATIONS:\n",
      "- Hydrochlorothiazide 25 MG Oral Tablet (1985–2016)\n",
      "- lisinopril 10 MG Oral Tablet (1985–2016)\n",
      "- ferrous sulfate 325 MG Oral Tablet (1986–ongoing)\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (20/20 correct)\n",
      "  30/50... (29/30 correct)\n",
      "  40/50... (39/40 correct)\n",
      "  50/50... (47/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.940\n",
      "   precision: 1.000\n",
      "      recall: 0.880\n",
      "          f1: 0.936\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[25  0]\n",
      " [ 3 22]]\n"
     ]
    }
   ],
   "source": [
    "strategy_d_metrics, strategy_d_cache = await run_opus_benchmark(\n",
    "    \"D: Structured Diff-Friendly\",\n",
    "    summarize_diff_friendly,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r81y9l0gjqn",
   "metadata": {},
   "source": [
    "## 8. Strategy E: Haiku LLM Summarizer (~500 tokens)\n",
    "\n",
    "Instead of hand-crafted rules, use Claude Haiku as the summarizer. Feed it raw patient records and ask for a ~500-word clinical summary optimized for entity resolution.\n",
    "\n",
    "**Approach:**\n",
    "1. Format raw records into text input for Haiku\n",
    "2. Pre-build a cache of Haiku summaries for all unique record_ids in benchmark pairs\n",
    "3. Wrap the cache in a sync function for `run_opus_benchmark()`\n",
    "\n",
    "This tests whether an LLM can produce better summaries than rule-based strategies by learning what matters for patient matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "jpyk1ouwqqf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Haiku cache for 95 unique record_ids...\n",
      "  10/95 done\n",
      "  20/95 done\n",
      "  30/95 done\n",
      "  40/95 done\n",
      "  50/95 done\n",
      "  60/95 done\n",
      "  70/95 done\n",
      "  80/95 done\n",
      "  90/95 done\n",
      "  95/95 done\n",
      "\n",
      "Haiku cache built: 95 summaries (0 errors)\n",
      "Tokens per summary: mean=1260, median=1296, max=2280\n"
     ]
    }
   ],
   "source": [
    "async def call_haiku(prompt: str, system_prompt: str = \"\", retries: int = 3) -> str:\n",
    "    \"\"\"Call Claude Haiku via claude-agent-sdk with retry on failure.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            result_parts = []\n",
    "            async for message in query(\n",
    "                prompt=prompt,\n",
    "                options=ClaudeAgentOptions(\n",
    "                    model=\"claude-haiku-4-5-20251001\",\n",
    "                    max_turns=1,\n",
    "                    allowed_tools=[],\n",
    "                    system_prompt=system_prompt,\n",
    "                ),\n",
    "            ):\n",
    "                if hasattr(message, 'content'):\n",
    "                    if isinstance(message.content, list):\n",
    "                        for block in message.content:\n",
    "                            if hasattr(block, 'text'):\n",
    "                                result_parts.append(block.text)\n",
    "                    elif isinstance(message.content, str):\n",
    "                        result_parts.append(message.content)\n",
    "            return \"\\n\".join(result_parts)\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                wait = 2 ** (attempt + 1)\n",
    "                print(f\"    Retry {attempt+1}/{retries-1} after error: {e!r} (waiting {wait}s)\")\n",
    "                await asyncio.sleep(wait)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "RAW_SECTION_CAP = 50  # max rows per section in raw records for Haiku input\n",
    "\n",
    "\n",
    "def format_raw_records(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Format raw patient records as text input for Haiku summarization.\"\"\"\n",
    "    records = get_patient_records(patient_id, facility_id, medical_records)\n",
    "    sections = []\n",
    "\n",
    "    for key, label in [\n",
    "        ('conditions', 'CONDITIONS'),\n",
    "        ('medications', 'MEDICATIONS'),\n",
    "        ('allergies', 'ALLERGIES'),\n",
    "        ('observations', 'OBSERVATIONS'),\n",
    "        ('procedures', 'PROCEDURES'),\n",
    "        ('encounters', 'ENCOUNTERS'),\n",
    "        ('immunizations', 'IMMUNIZATIONS'),\n",
    "        ('careplans', 'CARE PLANS'),\n",
    "        ('devices', 'DEVICES'),\n",
    "        ('imaging_studies', 'IMAGING'),\n",
    "    ]:\n",
    "        df = records.get(key)\n",
    "        if df is not None and not df.empty:\n",
    "            lines = [f\"=== {label} ({len(df)} rows) ===\"]\n",
    "            for _, row in df.head(RAW_SECTION_CAP).iterrows():\n",
    "                parts = []\n",
    "                for col in df.columns:\n",
    "                    val = row[col]\n",
    "                    if pd.notna(val) and str(val).strip():\n",
    "                        parts.append(f\"{col}={val}\")\n",
    "                lines.append(\"  \" + \" | \".join(parts))\n",
    "            if len(df) > RAW_SECTION_CAP:\n",
    "                lines.append(f\"  ... and {len(df) - RAW_SECTION_CAP} more rows\")\n",
    "            sections.append(\"\\n\".join(lines))\n",
    "\n",
    "    return \"\\n\\n\".join(sections) if sections else \"No records available.\"\n",
    "\n",
    "\n",
    "HAIKU_SUMMARIZER_PROMPT = \"\"\"You are a medical record summarizer for an entity resolution system that matches patient records across facilities.\n",
    "\n",
    "Given raw medical records for one patient at one facility, produce a concise clinical summary (~500 words) that preserves the features most useful for determining whether two records belong to the same person.\n",
    "\n",
    "PRIORITIZE these highly discriminative features:\n",
    "- Specific chronic conditions with onset dates (e.g., \"Type 2 diabetes diagnosed 2018\")\n",
    "- Medications with exact dosages and time periods (e.g., \"Metformin 500mg since 2018\")\n",
    "- Allergies with specific reactions and severity\n",
    "- Procedures with exact dates (especially rare/distinctive ones)\n",
    "- Key lab values and vitals with dates (HbA1c, cholesterol, BMI trends)\n",
    "- Immunization dates\n",
    "\n",
    "OMIT or minimize:\n",
    "- Generic social findings (employment status, education level, stress)\n",
    "- Routine screening procedures that appear on most patients\n",
    "- Encounter metadata without clinical content\n",
    "- Care plan boilerplate\n",
    "\n",
    "Format as a structured clinical summary with clear section headers. Be specific — exact dates, dosages, and values matter more than general descriptions.\"\"\"\n",
    "\n",
    "\n",
    "# Build haiku_cache for all unique record_ids in benchmark pairs\n",
    "unique_rids = set()\n",
    "for r1, r2, _ in benchmark_pairs:\n",
    "    unique_rids.add(r1)\n",
    "    unique_rids.add(r2)\n",
    "unique_rids = sorted(unique_rids)\n",
    "\n",
    "print(f\"Building Haiku cache for {len(unique_rids)} unique record_ids...\")\n",
    "\n",
    "haiku_cache = {}\n",
    "errors = 0\n",
    "for i, rid in enumerate(unique_rids):\n",
    "    if rid not in record_map:\n",
    "        continue\n",
    "    pid, fid = record_map[rid]\n",
    "    raw_text = format_raw_records(pid, fid, medical_records)\n",
    "    prompt = f\"Summarize the following patient records:\\n\\n{raw_text}\"\n",
    "    try:\n",
    "        summary = await call_haiku(prompt, system_prompt=HAIKU_SUMMARIZER_PROMPT)\n",
    "        haiku_cache[rid] = summary\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"  FAILED {rid}: {e!r}\")\n",
    "        haiku_cache[rid] = \"Summary unavailable due to error.\"\n",
    "\n",
    "    if (i + 1) % 10 == 0 or (i + 1) == len(unique_rids):\n",
    "        print(f\"  {i+1}/{len(unique_rids)} done\")\n",
    "\n",
    "print(f\"\\nHaiku cache built: {len(haiku_cache)} summaries ({errors} errors)\")\n",
    "token_counts = [count_tokens(s) for s in haiku_cache.values()]\n",
    "print(f\"Tokens per summary: mean={np.mean(token_counts):.0f}, \"\n",
    "      f\"median={np.median(token_counts):.0f}, max={max(token_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "p0o210ws57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  E: Haiku LLM Summarizer\n",
      "============================================================\n",
      "Tokens per summary: mean=1260, median=1296, max=2280\n",
      "Tokens per pair:    mean=2525, max=3658\n",
      "\n",
      "Example summary (facility_004_5a9d98df-4309-437e-c91f-6d45126e6101):\n",
      "----------------------------------------\n",
      "# Clinical Summary\n",
      "\n",
      "**Patient ID:** 5a9d98df-4309-437e-c91f-6d45126e6101  \n",
      "**Facility:** facility_004  \n",
      "**Record Period:** 1978–2015\n",
      "\n",
      "---\n",
      "\n",
      "## Chronic Conditions\n",
      "\n",
      "**Essential Hypertension**\n",
      "- Onset: November 27, 1985\n",
      "- Status: Active/ongoing throughout record period\n",
      "- Treatment initiated immediately upon diagnosis\n",
      "\n",
      "**Obesity**\n",
      "- BMI ≥30 documented: January 6, 1993\n",
      "- Status: Chronic, documented at wellness visits\n",
      "\n",
      "**Anemia**\n",
      "- Referenced in ambulatory encounter: December 10, 1986\n",
      "- Associated with iron supplementation therapy\n",
      "\n",
      "---\n",
      "\n",
      "## Medications\n",
      "\n",
      "**Antihypertensive Regimen (since 1985)**\n",
      "- **Hydrochlorothiazide 25 mg** oral tablet: November 27, 1985–present (continuing through 2009 documented)\n",
      "  - Dosage stable throughout; 4 dispensations per year typical\n",
      "- **Lisinopril 10 mg** oral tablet: November 27, 1985–present (continuing through 2009 documented)\n",
      "  - Dosage stable throughout; 4 dispensations per year typical\n",
      "\n",
      "**Iron Supplementation**\n",
      "- **Ferrous sulfate 325 mg** oral tablet: December 10, 1986 onward\n",
      "  - High dispensation volume (476 dispenses documented in single record)\n",
      "  - Indicates long-term anemia management\n",
      "\n",
      "---\n",
      "\n",
      "## Obstetric/Gynecological History\n",
      "\n",
      "**Miscarriage, First Trimester**\n",
      "- Date: May 10, 1989\n",
      "- Encounter type: Ambulatory prenatal/obstetric visit\n",
      "- Prior encounter (May 10, 1989) documented \"Normal pregnancy\" immediately preceding miscarriage\n",
      "\n",
      "**Tubal Ligation**\n",
      "- Date: June 21, 1996\n",
      "- Encounter type: Inpatient surgical admission (June 21–22, 1996)\n",
      "- Reason: \n",
      "... (truncated)\n",
      "\n",
      "Running 50 pairs through Opus...\n",
      "  10/50... (10/10 correct)\n",
      "  20/50... (20/20 correct)\n",
      "  30/50... (30/30 correct)\n",
      "  40/50... (40/40 correct)\n",
      "  50/50... (49/50 correct)\n",
      "\n",
      "Results (50 scored / 0 skipped / 0 errors / 50 total):\n",
      "    accuracy: 0.980\n",
      "   precision: 1.000\n",
      "      recall: 0.960\n",
      "          f1: 0.980\n",
      "\n",
      "Confusion Matrix (rows=actual, cols=predicted):\n",
      "[[25  0]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "def summarize_haiku_cached(patient_id, facility_id, medical_records):\n",
    "    \"\"\"Look up pre-built Haiku summary from cache.\"\"\"\n",
    "    rid = facility_id + '_' + str(patient_id)\n",
    "    return haiku_cache.get(rid, \"No summary available.\")\n",
    "\n",
    "strategy_e_metrics, strategy_e_cache = await run_opus_benchmark(\n",
    "    \"E: Haiku LLM Summarizer\",\n",
    "    summarize_haiku_cached,\n",
    "    benchmark_pairs, record_map, medical_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb8546",
   "metadata": {},
   "source": [
    "## 9. Comparison\n",
    "\n",
    "Side-by-side results for all strategies. The goal is to find the best F1 score while keeping tokens reasonable (~500–2000 per summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy                         Tok/Sum   Tok/Pair     Acc    Prec  Recall      F1   F1/kTok\n",
      "===============================================================================================\n",
      "Baseline (full summary)             1019       2048   0.940   1.000   0.880   0.936     0.457\n",
      "A: Temporal-Enhanced                2315       4564   0.940   1.000   0.880   0.936     0.205\n",
      "B: Identity-Focused                  145        288   0.920   0.957   0.880   0.917     3.185\n",
      "C: Compact Raw                      1846       3694   0.920   1.000   0.840   0.913     0.247\n",
      "D: Structured Diff-Friendly          760       1508   0.940   1.000   0.880   0.936     0.621\n",
      "E: Haiku LLM Summarizer             1260       2525   0.980   1.000   0.960   0.980     0.388\n",
      "\n",
      "Best F1:         E: Haiku LLM Summarizer (F1=0.980, 2525 tok/pair)\n",
      "Best F1/token:   B: Identity-Focused (F1=0.917, 288 tok/pair)\n",
      "\n",
      "Reference: Raw records (Opus) = F1 0.980 at ~12,157 tok/pair\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'Strategy':<30s}  {'Tok/Sum':>8s}  {'Tok/Pair':>9s}  \"\n",
    "      f\"{'Acc':>6s}  {'Prec':>6s}  {'Recall':>6s}  {'F1':>6s}  {'F1/kTok':>8s}\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "for name, m in all_results.items():\n",
    "    f1_per_ktok = m['f1'] / (m['tokens_pair_mean'] / 1000) if m['tokens_pair_mean'] > 0 else 0\n",
    "    print(f\"{name:<30s}  {m['tokens_mean']:>8.0f}  {m['tokens_pair_mean']:>9.0f}  \"\n",
    "          f\"{m['accuracy']:>6.3f}  {m['precision']:>6.3f}  {m['recall']:>6.3f}  \"\n",
    "          f\"{m['f1']:>6.3f}  {f1_per_ktok:>8.3f}\")\n",
    "\n",
    "# Identify best strategies\n",
    "best_f1 = max(all_results.items(), key=lambda x: x[1]['f1'])\n",
    "best_efficiency = max(all_results.items(),\n",
    "                      key=lambda x: x[1]['f1'] / max(x[1]['tokens_pair_mean'], 1))\n",
    "\n",
    "print(f\"\\nBest F1:         {best_f1[0]} (F1={best_f1[1]['f1']:.3f}, \"\n",
    "      f\"{best_f1[1]['tokens_pair_mean']:.0f} tok/pair)\")\n",
    "print(f\"Best F1/token:   {best_efficiency[0]} (F1={best_efficiency[1]['f1']:.3f}, \"\n",
    "      f\"{best_efficiency[1]['tokens_pair_mean']:.0f} tok/pair)\")\n",
    "\n",
    "# Compare to raw records ceiling\n",
    "print(f\"\\nReference: Raw records (Opus) = F1 0.980 at ~12,157 tok/pair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747715f",
   "metadata": {},
   "source": [
    "## 10. Recommendations\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "Review the comparison table above to identify:\n",
    "\n",
    "1. **Best absolute F1**: Which strategy gets closest to the raw-records ceiling (F1=0.980)?\n",
    "2. **Best F1-per-token efficiency**: Which strategy gives the best accuracy per token budget?\n",
    "3. **Practical choice**: For fine-tuning Gemma 1B (context window ~2048), which strategy fits while maximizing signal?\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Based on results:\n",
    "- If a strategy beats F1=0.889 (current production), update `llm-entity-resolution/src/summarize.py`\n",
    "- Consider combining the best elements from multiple strategies\n",
    "- Use the winning strategy to generate training data for Gemma 1B fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
