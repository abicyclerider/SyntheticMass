# MedGemma 1.5 4B (full precision) â€” with thinking suppressed
#
# On the full precision model, the system prompt is what triggers chain-of-thought
# reasoning. The base model (medgemma:1.5-4b) includes a system prompt, and
# `FROM model_name` inherits it even with `SYSTEM ""`. Using `FROM <blob>` avoids
# inheriting the system prompt, which suppresses thinking.
#
# Build: ollama create medgemma:1.5-4b-fast -f ollama/Modelfile.no-thinking-full
# Requires: medgemma:1.5-4b must already be pulled (provides the blob)

FROM /Users/alex/.ollama/models/blobs/sha256-86ef3b31ec0d60c675143e3193cbdfac2d3848b0e49e745ba4f76d35014431bf

TEMPLATE """{{ if .System }}<start_of_turn>system
{{ .System }}<end_of_turn>
{{ end }}{{ if .Prompt }}<start_of_turn>user
{{ .Prompt }}<end_of_turn>
{{ end }}<start_of_turn>model
{{ .Response }}<end_of_turn>
"""

PARAMETER stop <start_of_turn>
PARAMETER stop <end_of_turn>
PARAMETER temperature 0.7
PARAMETER top_k 40
PARAMETER top_p 0.9
