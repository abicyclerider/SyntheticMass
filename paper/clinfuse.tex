\documentclass[10pt,twocolumn]{article}

% --- Page geometry: tight for 3 pages ---
\usepackage[
  letterpaper,
  top=0.65in, bottom=0.65in, left=0.6in, right=0.6in,
  columnsep=0.25in
]{geometry}

% --- Packages ---
\usepackage[T1]{fontenc}
\usepackage{times}              % compact serif font
\usepackage{microtype}          % better spacing
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, calc, shapes.geometric, fit}
\usepackage{caption}
\usepackage[colorlinks,citecolor=blue!70!black,urlcolor=blue!70!black,linkcolor=black]{hyperref}
\usepackage{enumitem}
\setlist{nosep, leftmargin=1.2em}
\usepackage{titlesec}
\usepackage{float}
\usepackage{balance}

% --- Compact sections ---
\titleformat{\section}{\bfseries\normalsize}{\thesection.}{0.4em}{}
\titlespacing*{\section}{0pt}{6pt plus 2pt}{2pt plus 1pt}
\titleformat{\subsection}{\bfseries\small}{\thesubsection}{0.4em}{}
\titlespacing*{\subsection}{0pt}{4pt plus 2pt}{1pt plus 1pt}
\titleformat{\subsubsection}[runin]{\bfseries\small}{}{0em}{}[.]
\titlespacing*{\subsubsection}{0pt}{3pt}{0.4em}

% --- Compact title ---
\makeatletter
\renewcommand{\maketitle}{%
  \twocolumn[%
    \begin{center}
      {\Large\bfseries \@title \par}
      \vskip 4pt
      {\normalsize \@author \par}
      \vskip 8pt
    \end{center}
  ]%
}
\makeatother

% --- Compact captions ---
\captionsetup{font=small, labelfont=bf, skip=4pt, belowskip=-4pt}

% --- Colors for figure ---
\definecolor{tiergreen}{HTML}{2E7D32}       % Tier 2 auto-match (green)
\definecolor{tieramber}{HTML}{E65100}       % Tier 3 gray zone / LLM (amber)
\definecolor{tierred}{HTML}{C62828}         % Tier 2 auto-reject (red)
\definecolor{tierblue}{HTML}{1565C0}        % Tier 1 & 2 infrastructure (blue)

% --- Footnote size reduction ---
\renewcommand{\footnotesize}{\fontsize{7.5pt}{9pt}\selectfont}

\begin{document}

\title{ClinFuse: Patient Entity Resolution\\Powered by MedGemma Clinical Reasoning}
\author{Alexander Rider}
\date{}
\maketitle

% =====================================================================
%  1  PROBLEM STATEMENT
% =====================================================================
\section{Problem Statement}

A cardiac arrest patient's record was confused with another patient's---one who carried a do-not-resuscitate order. The care team withheld life-saving treatment~\cite{ecri2016}. When healthcare systems can't reliably match records to the right patient, people die. Patients with duplicate charts---the most common form of this identity failure---are five times more likely to die during hospitalization~\cite{western2026}. Across 7{,}613 wrong-patient events at 181 healthcare organizations, 9\% resulted in patient harm~\cite{ecri2016}. For the emergency department registrar matching an unconscious patient to their records, or the IT staff reconciling patient feeds from dozens of hospitals, these are not edge cases---they are daily realities.

Duplicate records aren't just dangerous---they're pervasive. An estimated 8--12\% of hospital records are duplicates~\cite{morris2016}, costing the U.S.\ healthcare system \$6.7 billion annually~\cite{blackbook2018}. Match accuracy averages 80--90\% within institutions but falls to 50\% in cross-organizational exchange~\cite{onc2014}---meaning roughly half of cross-organizational duplicates go unresolved. The MATCH~IT Act (H.R.~2002, 2025) sets a 99.9\% matching target~\cite{matchit2025}, and TEFCA v2.1 makes cross-organizational matching critical national infrastructure~\cite{tefca2024}. Closing this gap would resolve 99.8\% of currently-missed cross-organizational duplicates (from 50\% unresolved to 0.1\%). Even conservatively attributing half of the \$6.7B burden to cross-organizational failures, this represents over \$3~billion in recoverable annual waste---alongside the patient harm that fragmented records cause.

The barrier isn't better algorithms---it's better information. Any method relying exclusively on demographic fields faces an accuracy ceiling imposed by field quality---over half of duplicate pairs contain misspelled names or mismatched identifiers~\cite{morris2016}. The missing signal is \emph{clinical context}: the full breadth of a patient's medical record---conditions, medications, allergies, observations, and procedures---provides a powerful signal for resolving patient identity, regardless of demographic discrepancies. Yet no production entity resolution system exploits this signal: probabilistic and rule-based matchers lack the medical knowledge to interpret clinical histories as identity evidence.

% =====================================================================
%  2  OVERALL SOLUTION
% =====================================================================
\section{Overall Solution}

Interpreting this clinical context as identity evidence requires medical reasoning---exactly the capability MedGemma~\cite{medgemma} provides. To demonstrate its potential for patient entity resolution, we embed it in ClinFuse, a three-tier pipeline that augments fast probabilistic matching with MedGemma's clinical reasoning, invoked selectively for ambiguous cases. Figure~\ref{fig:architecture} illustrates the architecture.

\subsubsection{Tier~1: Blocking} All records enter Splink~v4~\cite{splink}, which first applies blocking rules on demographic fields to generate candidate pairs without exhaustive $O(n^2)$ comparisons.

\subsubsection{Tier~2: Demographic Triage} Candidate pairs are scored via Fellegi--Sunter~\cite{fellegi1969} probabilistic linkage using expectation-maximization with Jaro--Winkler string similarity and term-frequency adjustment. Pairs with high match probability are auto-matched; pairs with very low probability are auto-rejected. The remaining ambiguous ``gray zone'' pairs proceed to clinical review.

\subsubsection{Tier~3: Clinical LLM} Gray-zone pairs receive structured clinical summaries and are classified by a fine-tuned MedGemma~4B model, whose medical pretraining enables it to interpret clinical histories as identity evidence. The model's generative head is replaced with a binary classification layer. Each patient's clinical history is summarized into a compact format: conditions grouped by onset year, medications with date ranges, sorted allergies, latest values per vital sign, and procedures with years. The model sees two parallel summaries and classifies whether they describe the same patient (Figure~\ref{fig:example}). A Bayesian prior correction first shifts the LLM logit from the balanced training distribution to the gray zone's lower true-match rate, preventing overconfident match predictions. The corrected LLM logit and Splink match probability are then combined in log-odds space using interpretable linear weights.

\subsubsection{Golden Records} Matched pairs form a graph whose connected components yield patient clusters. Field-level conflict resolution applies majority voting with domain heuristics (e.g., preferring longer address forms), producing a deduplicated Master Patient Index (MPI).

\noindent\textbf{MedGemma as Clinical Reasoner.}
Prior work has applied LLMs to adjacent healthcare tasks---MedLink uses
diagnosis-code embeddings for de-identified record
linkage~\cite{medlink2023}, and PRISM fine-tunes an LLM for clinical trial
matching~\cite{prism2024}---but neither addresses patient-to-patient identity
resolution using clinical narratives. In general-domain entity resolution,
large language models such as GPT-4 achieve strong zero-shot matching that
rivals fine-tuned pre-trained language models~\cite{peeters2023}, and
cost-efficient frameworks selectively route only uncertain pairs to an
LLM~\cite{booster2024,coling2025}---an architecture ClinFuse shares. However,
these approaches rely on cloud-hosted models with 70B--175B+ parameters,
incurring per-query costs, introducing latency, and---critically for
healthcare---requiring patient data to leave the facility, making them
challenging under HIPAA and GDPR. Beyond privacy, the scale of the matching
problem favors small, specialized models over large general-purpose ones:
matching 1~million records requires evaluating nearly 500~billion pairwise
comparisons---a volume where per-query API costs become prohibitive, demanding a
system that screens cheaply at scale and reserves clinical reasoning for only
the cases that need it. Fine-tuned models of comparable size (e.g.,
Mistral-7B-Instruct, Qwen-14B) lack medical domain knowledge and underperform
on clinical text~\cite{prism2024}. A recent healthcare-specific approach
fine-tunes PubMedBERT with contrastive learning for patient linkage at
scale~\cite{pubmedbert_hybrid2025}, and is deployable on-premises, but
operates exclusively on demographic fields without leveraging clinical context.

MedGemma is the first medical foundation model that combines clinical reasoning
with edge-deployable size, making it uniquely suited for healthcare entity
resolution where privacy constraints rule out cloud models. Pretrained for
clinical question answering and medical image interpretation, patient entity
resolution is entirely outside its pretraining distribution---yet its medical
language understanding enables it to recognize that ``Essential Hypertension''
and ``Hypertension'' are the same condition, or that overlapping medication
regimens constitute strong identity evidence. At 4B parameters it runs on a single consumer GPU
({\raise.17ex\hbox{$\scriptstyle\sim$}}\$1{,}500), requires no cloud
connectivity, and its medical pretraining provides the clinical reasoning
necessary to interpret disease trajectories, medication overlaps, and vital
sign concordance as identity evidence. LoRA fine-tuning successfully adapts it
to pairwise classification, achieving 0.98 F1 on held-out evaluation
data---demonstrating that medical pretraining transfers effectively to this
novel task.

% --- FIGURE 1: Architecture ---
\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{fig_architecture.pdf}
\caption{ClinFuse three-tier architecture. \textbf{Tier~1} generates candidate pairs via blocking rules. \textbf{Tier~2} scores pairs probabilistically; high-confidence matches (\textcolor{tiergreen}{green}) and clear non-matches (\textcolor{tierred}{red}) are resolved automatically. Only ambiguous gray-zone pairs (\textcolor{tieramber}{amber}) route through the \textbf{Tier~3} clinical LLM for final resolution.}
\label{fig:architecture}
\end{figure*}

% =====================================================================
%  3  TECHNICAL DETAILS
% =====================================================================
\section{Technical Details}

\subsection{Data Generation and Augmentation}

Synthea~\cite{walonoski2018} generates realistic synthetic patients with clinically coherent histories spanning conditions, medications, allergies, observations, and procedures. An augmentation pipeline distributes each patient's records across multiple simulated facilities and injects demographic errors: name variations (nickname substitution, typos, maiden name usage), address errors (abbreviation, format variation), date perturbations, identifier errors (SSN transposition, digit substitution), and formatting noise---mirroring documented real-world error patterns~\cite{morris2016}. Separate datasets are generated for training (30{,}000 patients) and evaluation (2{,}500 patients, 6{,}264 records across 5 facilities).

\subsection{Adapting MedGemma for Entity Resolution}

\textbf{Text-only adaptation.}
MedGemma~4B is a multimodal model with both vision and text encoders. Since our task is text-only, we strip the vision tower before fine-tuning, reducing from 4.2B to 3.88B parameters while preserving the medical language understanding from pretraining.

\textbf{LoRA fine-tuning with classification head.}
We apply LoRA~\cite{hu2021lora} (Low-Rank Adaptation) in bf16 precision targeting attention and MLP projection layers, and replace the generative language-model head with a two-class classification layer that outputs match/non-match logits directly---bypassing text generation entirely. Fine-tuned classification heads significantly outperform zero-shot prompting for binary tasks~\cite{finetune_vs_prompt} while being orders of magnitude faster at inference~\cite{cls_head_efficiency}. Training uses balanced match/non-match pairs generated from augmented Synthea records.
\subsection{Results}\label{sec:results}

Table~\ref{tab:results} compares Splink-only matching against the full ClinFuse pipeline on 6{,}264 synthetic records (2{,}500 patients across 5 facilities) under deliberately adversarial conditions: each record carries 8 to 12 demographic errors and each patient's clinical history is split across a random number of facilities. These conditions stress-test the approach rather than simulate typical production data.

\begin{table}[h]
\centering\small
\caption{Entity resolution performance. Splink-only uses the 0.99 auto-match threshold. ClinFuse adds MedGemma gray-zone classification and score fusion.}
\label{tab:results}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{Splink Only} & \textbf{ClinFuse} \\
\midrule
Precision & 0.910 & \textbf{0.922} \\
Recall & 0.467 & \textbf{0.910} \\
F1 & 0.617 & \textbf{0.916} \\
\midrule
\multicolumn{3}{@{}l@{}}{\textit{Operational statistics (ClinFuse):}} \\
\multicolumn{2}{@{}l@{}}{~~Gray-zone pairs classified by LLM} & 151{,}309 \\
\multicolumn{2}{@{}l@{}}{~~LLM-recovered matches} & 2{,}702 \\
\bottomrule
\end{tabular}
\end{table}

At the 0.99 threshold, Splink alone achieves high precision (0.910) but captures fewer than half of true matches---the strict threshold, combined with heavy demographic errors (8--12 per record), leaves most true pairs in the gray zone. MedGemma's clinical understanding---recognizing matching disease trajectories and overlapping medication regimens---nearly doubles recall from 0.467 to 0.910, recovering 2{,}702 matches that demographics alone could not resolve. Precision remains comparable (0.922 vs.\ 0.910), demonstrating that the Bayesian prior correction and weighted log-odds fusion effectively suppress false merges.

% --- FIGURE 2: Clinical Summary Example ---
\begin{figure}[t]
\centering
\footnotesize
\begin{tabular}{@{}p{0.97\columnwidth}@{}}
\toprule
\textbf{Record A} (Facility 1) \\
\midrule
\texttt{CONDITIONS:} \\
\texttt{~~2018: Hypertension *; Type 2 Diabetes *} \\
\texttt{~~2020: Acute Bronchitis} \\
\texttt{MEDICATIONS:} \\
\texttt{- Metformin 500mg (2018--ongoing)} \\
\texttt{- Lisinopril 10mg (2018--ongoing)} \\
\texttt{OBSERVATIONS:} \\
\texttt{- A1c: 7.2\% (2024-06), 7.0\% (2023-12)} \\
\midrule
\textbf{Record B} (Facility 3) \\
\midrule
\texttt{CONDITIONS:} \\
\texttt{~~2018: Essential Hypertension *; Diabetes *} \\
\texttt{~~2020: Acute Bronchitis} \\
\texttt{MEDICATIONS:} \\
\texttt{- Metformin Hydrochloride 500mg (2018--ongoing)} \\
\texttt{- Lisinopril 10mg (2019--ongoing)} \\
\texttt{OBSERVATIONS:} \\
\texttt{- A1c: 7.2\% (2024-06), 7.0\% (2023-12)} \\
\bottomrule
\end{tabular}
\caption{Structured clinical summary pair as input to the MedGemma classifier. Despite demographic discrepancies (name typo + address abbreviation), the parallel clinical trajectories---identical chronic conditions, overlapping medications, and matching vitals---enable the model to correctly identify a match.}
\label{fig:example}
\end{figure}

\subsection{Deployment and Feasibility}

\textbf{Hardware.} MedGemma 4B runs in bf16 precision on a single consumer GPU (e.g., RTX~3090, {\raise.17ex\hbox{$\scriptstyle\sim$}}\$1{,}500). No cloud API dependency.

\textbf{Privacy by design.} All inference can run locally---no patient data needs to leave the facility. This supports HIPAA and GDPR compliance and enables air-gapped deployment.

\textbf{Cost at scale.} The tiered architecture keeps GPU costs proportional to ambiguity, not data size: Splink scores all candidate pairs in seconds, and only gray-zone pairs require LLM inference. The fraction reaching the LLM depends on data quality and threshold configuration---from under 5\% with clean demographics to nearly all pairs in heavily degraded data. The pipeline supports both batch processing for MPI deduplication and near-real-time matching for point-of-care patient registration.

\textbf{Integration.} Input is standard HL7/FHIR demographic and clinical fields. Output is a deduplicated Master Patient Index---a drop-in replacement for existing MPI systems. Match and reject thresholds are configurable, allowing operators to tune the precision--recall trade-off for their clinical context.

\textbf{Open source and reproducible.} The complete pipeline is implemented as a DVC directed acyclic graph with separate training and inference tracks. All stages run in Docker containers. Source code, model, adapter, and dataset are publicly available (see Acknowledgments).

\subsection{Limitations and Future Work}

\textbf{Limitations.} ClinFuse is evaluated on synthetic data (Synthea), which, while clinically realistic, may not capture all real-world patterns such as identity theft, deliberate data falsification, or extreme data sparsity in safety-net hospitals. The fusion weights are tuned for this dataset and would require calibration on real EHR data. Synthetic evaluation data may differ in difficulty from real-world data, so reported metrics demonstrate the approach's viability rather than guarantee production performance.

\textbf{Future work.} Key directions include: (1)~validation on de-identified real EHR data to confirm generalization; (2)~\emph{tiered model escalation} where uncertain pairs route from smaller models to larger ones and ultimately to human-in-the-loop review, creating a graduated safety net for the most ambiguous cases; (3)~\emph{multimodal resolution} leveraging MedGemma's vision capabilities to incorporate radiology images and scanned documents as additional identity signals; (4)~joint demographic--clinical fine-tuning in a single end-to-end model; and (5)~embedding-based candidate matching using learned patient representations for fast approximate nearest-neighbor search, replacing handcrafted blocking rules to scale to millions of records.

% =====================================================================
%  CONCLUSION
% =====================================================================
\section{Conclusion}

This work demonstrates that MedGemma---pretrained for clinical QA and medical imaging, never designed for entity resolution---can be effectively repurposed for patient identity matching through LoRA adaptation. Achieving 0.98 F1 on this novel pairwise classification task, its integration into the ClinFuse pipeline nearly doubles end-to-end recall from 0.467 to 0.910 while maintaining 92.2\% precision. The system runs entirely on-premises on a single consumer GPU, requires no cloud API, and invokes the LLM only for the small fraction of pairs that probabilistic matching cannot resolve. These properties---high accuracy, full privacy, low cost, and interpretable fusion---make MedGemma-powered entity resolution a practical path toward the 99.9\% matching accuracy that the MATCH~IT Act demands and that patient safety requires.

Entity resolution represents a genuinely novel application of MedGemma---repurposing medical language understanding for a task entirely outside the model's pretraining distribution. The success of this transfer suggests that medical foundation models have broader utility than their original design scope implies: clinical NLP capabilities can power infrastructure tasks that underpin the entire healthcare data ecosystem. As health information exchange scales under TEFCA, MedGemma's combination of clinical reasoning, edge deployability, and adaptability through parameter-efficient fine-tuning offers a foundation for safe, accurate, and privacy-preserving patient matching at national scale.

% =====================================================================
%  ACKNOWLEDGMENTS
% =====================================================================
\section*{Acknowledgments}

This work uses MedGemma~\cite{medgemma} (Google Health AI) as the foundation model and Splink~\cite{splink} for probabilistic linkage. Synthetic data generated with Synthea~\cite{walonoski2018}. Developed for the Kaggle MedGemma Impact Challenge~\cite{kaggle2026}.

\smallskip
\noindent\textbf{Resources:}\\
Code: \url{https://github.com/abicyclerider/clinfuse}\\
Model: \url{https://huggingface.co/abicyclerider/medgemma-4b-entity-resolution-text-only}\\
Dataset: \url{https://huggingface.co/datasets/abicyclerider/entity-resolution-pairs}\\
Video: \textit{[URL TBD before submission]}

% =====================================================================
%  REFERENCES
% =====================================================================
\balance
\begingroup
\footnotesize
\begin{thebibliography}{99}
\setlength{\itemsep}{0pt}\setlength{\parsep}{0pt}\setlength{\parskip}{0pt}

\bibitem{ecri2016}
ECRI Institute PSO, ``Deep dive: Patient identification,'' 2016.

\bibitem{western2026}
J.~Western et al., ``SEE ALTERNATE MRN: Duplicate charts in hospitalized patients,'' \textit{BMJ Qual.\ Saf.}, 2026.

\bibitem{morris2016}
G.~Morris et al., ``Patient matching is a challenge,'' \textit{Perspect.\ HIM}, 2016.

\bibitem{blackbook2018}
Black Book Market Research, ``Provider interoperability and patient record error rates,'' 2018.

\bibitem{onc2014}
ONC, ``Patient identification and matching final report,'' 2014.

\bibitem{matchit2025}
U.S.\ Congress, ``MATCH IT Act,'' H.R.~2002, 2025.

\bibitem{tefca2024}
ONC, ``TEFCA v2.1,'' 2024.

\bibitem{fellegi1969}
I.~P. Fellegi and A.~B. Sunter, ``A theory for record linkage,'' \textit{JASA}, 64(328):1183--1210, 1969.

\bibitem{medlink2023}
Z.~Wu et al., ``MedLink: De-identified patient record linkage,'' \textit{Proc.\ KDD}, 2023.

\bibitem{prism2024}
B.~Qian et al., ``PRISM: Patient records interpretation for clinical trial matching using LLMs,'' \textit{npj Digit.\ Med.}, 7, 2024.

\bibitem{medgemma}
Google Health AI, ``MedGemma model card,'' 2025.

\bibitem{splink}
R.~Linacre et al., ``Splink: Probabilistic record linkage at scale,'' \textit{Int.\ J.\ Pop.\ Data Sci.}, 2022.

\bibitem{walonoski2018}
J.~Walonoski et al., ``Synthea: Generating synthetic patients and EHRs,'' \textit{JAMIA}, 25(3):230--238, 2018.

\bibitem{hu2021lora}
E.~J. Hu et al., ``LoRA: Low-rank adaptation of large language models,'' \textit{arXiv:2106.09685}, 2021.

\bibitem{finetune_vs_prompt}
S.~Gao et al., ``Fine-tuned small LLMs vs.\ zero-shot large LLMs for classification,'' \textit{arXiv:2406.08660}, 2024.

\bibitem{cls_head_efficiency}
S.~Singh et al., ``Classification heads: 130x faster than prompting,'' \textit{arXiv:2411.05045}, 2024.

\bibitem{kaggle2026}
F.~Mahvar et al., ``MedGemma Impact Challenge,'' Kaggle, 2026.

\bibitem{peeters2023}
R.~Peeters and C.~Bizer, ``Entity matching using large language models,'' \textit{arXiv:2310.11244}, 2023.

\bibitem{booster2024}
Y.~Li et al., ``On leveraging large language models for enhancing entity resolution: A cost-efficient approach,'' \textit{arXiv:2401.03426}, 2024.

\bibitem{coling2025}
T.~Wang et al., ``Match, compare, or select? An investigation of large language models for entity matching,'' \textit{Proc.\ COLING}, 2025.

\bibitem{pubmedbert_hybrid2025}
C.~Cao et al., ``Linking patient records at scale with a hybrid approach combining contrastive learning and deterministic rules,'' \textit{medRxiv}, 2025.

\end{thebibliography}
\endgroup

\end{document}
